#!/usr/bin/env python3
"""
çœŸå¯¦æ•¸æ“šçµ±ä¸€æ”¶é›†å™¨ - Real Data Only Collector
çµ•å°ä¸ä½¿ç”¨ mock æ•¸æ“šï¼Œåƒ…æ”¶é›†ä¾†è‡ªå®˜æ–¹æ•¸æ“šæºçš„çœŸå¯¦æ•¸æ“š

é€™å€‹è…³æœ¬å°‡ï¼š
1. å¾çœŸå¯¦çš„ HKMAã€C&SD ç­‰å®˜æ–¹æ•¸æ“šæºæ”¶é›†æ•¸æ“š
2. é©—è­‰æ‰€æœ‰æ•¸æ“šéƒ½æ˜¯çœŸå¯¦çš„ï¼ˆé mockï¼‰
3. ç”Ÿæˆæ•¸æ“šè³ªé‡å ±å‘Š
4. å°‡çœŸå¯¦æ•¸æ“šä¿å­˜åˆ°é‡åŒ–äº¤æ˜“ç³»çµ±

è­¦å‘Š: ä»»ä½•ä½¿ç”¨ mock æ•¸æ“šçš„è¡Œç‚ºéƒ½æœƒè¢«æ‹’çµ•ä¸¦è¨˜éŒ„éŒ¯èª¤
"""

import asyncio
import sys
import logging
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Any
import pandas as pd
import json

# æ·»åŠ é©é…å™¨è·¯å¾‘
sys.path.append(str(Path(__file__).parent / 'adapters' / 'real_data'))

from hibor.hkma_hibor_adapter import HKMAHiborAdapter
from economic.csd_economic_adapter import CSDEconomicAdapter
from property.landreg_property_adapter import LandRegPropertyAdapter
from property.property_market_index_adapter import PropertyMarketIndexAdapter
from base_real_adapter import DataQualityReport, MockDataError

# é…ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('gov_crawler/logs/real_data_collection.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class RealDataOnlyCollector:
    """
    çœŸå¯¦æ•¸æ“šæ”¶é›†å™¨ - æ‹’çµ•æ‰€æœ‰ mock æ•¸æ“š
    """

    def __init__(self):
        self.adapters = {}
        self.collection_results = {}
        self.real_data_count = 0
        self.mock_data_attempts = 0

        # åˆå§‹åŒ–é©é…å™¨
        self._initialize_adapters()

    def _initialize_adapters(self):
        """åˆå§‹åŒ–æ‰€æœ‰çœŸå¯¦æ•¸æ“šé©é…å™¨"""
        logger.info("åˆå§‹åŒ–çœŸå¯¦æ•¸æ“šé©é…å™¨...")

        # åªèƒ½ä½¿ç”¨çœŸå¯¦æ•¸æ“šé©é…å™¨
        self.adapters = {
            'hibor': HKMAHiborAdapter(),
            'economic': CSDEconomicAdapter(),
            'property_landreg': LandRegPropertyAdapter(),
            'property_index': PropertyMarketIndexAdapter(),
        }

        # è¨˜éŒ„åˆå§‹åŒ–è­¦å‘Š
        for name, adapter in self.adapters.items():
            adapter.log_real_data_warning()

        logger.info(f"å·²åˆå§‹åŒ– {len(self.adapters)} å€‹çœŸå¯¦æ•¸æ“šé©é…å™¨")

    async def collect_all_real_data(self, start_date: str, end_date: str) -> Dict[str, Any]:
        """
        æ”¶é›†æ‰€æœ‰çœŸå¯¦æ•¸æ“š
        """
        logger.warning("=" * 80)
        logger.warning("é–‹å§‹æ”¶é›†çœŸå¯¦æ•¸æ“š - åš´æ ¼ç¦æ­¢ mock æ•¸æ“š")
        logger.warning("=" * 80)

        results = {
            'collection_time': datetime.now().isoformat(),
            'start_date': start_date,
            'end_date': end_date,
            'adapters_count': len(self.adapters),
            'successful_collections': 0,
            'failed_collections': 0,
            'total_records': 0,
            'real_data_confirmed': 0,
            'mock_data_rejected': 0,
            'data_sources': {},
            'quality_reports': {},
            'errors': []
        }

        async with RealDataAdapter('temp', 'temp') as temp:  # å‰µå»º session context
            for name, adapter in self.adapters.items():
                try:
                    logger.info(f"\næ­£åœ¨æ”¶é›† {name} çœŸå¯¦æ•¸æ“š...")
                    result = await self._collect_from_adapter(adapter, name, start_date, end_date)
                    results['data_sources'][name] = result
                    results['successful_collections'] += 1
                    results['total_records'] += len(result.get('data', []))
                    results['real_data_confirmed'] += result.get('real_data_count', 0)

                except MockDataError as e:
                    logger.error(f"ğŸš« {name}: Mock æ•¸æ“šéŒ¯èª¤ - {str(e)}")
                    results['mock_data_rejected'] += 1
                    results['errors'].append(f"{name}: {str(e)}")

                except Exception as e:
                    logger.error(f"âŒ {name}: æ”¶é›†å¤±æ•— - {str(e)}")
                    results['failed_collections'] += 1
                    results['errors'].append(f"{name}: {str(e)}")

        # é©—è­‰ç¸½é«”æ•¸æ“šè³ªé‡
        if results['mock_data_rejected'] > 0:
            logger.error("ğŸš¨ æª¢æ¸¬åˆ° mock æ•¸æ“šå˜—è©¦ï¼å·²æ‹’çµ•æ‰€æœ‰ mock æ•¸æ“š")
            logger.error("æ•¸æ“šè³ªé‡ç„¡æ³•ä¿è­‰ï¼Œå»ºè­°æª¢æŸ¥æ•¸æ“šæº")

        logger.info("\n" + "=" * 80)
        logger.info("çœŸå¯¦æ•¸æ“šæ”¶é›†å®Œæˆ")
        logger.info(f"æˆåŠŸ: {results['successful_collections']}/{len(self.adapters)}")
        logger.info(f"å¤±æ•—: {results['failed_collections']}")
        logger.info(f"æ‹’çµ• mock æ•¸æ“š: {results['mock_data_rejected']}")
        logger.info(f"ç¢ºèªçœŸå¯¦æ•¸æ“š: {results['real_data_confirmed']} æ¢è¨˜éŒ„")
        logger.info("=" * 80)

        return results

    async def _collect_from_adapter(self, adapter, name: str, start_date: str, end_date: str) -> Dict[str, Any]:
        """
        å¾å–®å€‹é©é…å™¨æ”¶é›†æ•¸æ“š
        """
        async with adapter:
            # æ¸¬è©¦é€£æ¥
            connection_ok = await adapter.test_connection()
            if not connection_ok:
                raise ConnectionError(f"ç„¡æ³•é€£æ¥åˆ° {name} æ•¸æ“šæº")

            # ç²å–çœŸå¯¦æ•¸æ“š
            df, quality_report = await adapter.collect_and_validate(start_date, end_date)

            if df.empty:
                raise ValueError(f"{name}: æœªç²å–åˆ°ä»»ä½•æ•¸æ“š")

            # å¼·åˆ¶é©—è­‰çœŸå¯¦æ•¸æ“š
            is_real = await adapter.validate_data_is_real(df)
            if not is_real:
                raise MockDataError(f"{name}: æ•¸æ“šé©—è­‰å¤±æ•— - å¯èƒ½åŒ…å« mock æ•¸æ“š")

            # ä¿å­˜æ•¸æ“š
            saved_file = adapter.save_data_with_quality(df, quality_report)

            # ç²å–æ•¸æ“šæºä¿¡æ¯
            source_info = adapter.get_data_source_info()

            result = {
                'name': name,
                'success': True,
                'records_count': len(df),
                'real_data_count': len(df),  # æ‰€æœ‰æ•¸æ“šéƒ½æ‡‰è©²æ˜¯çœŸå¯¦çš„
                'data_file': saved_file,
                'quality_report': quality_report.to_dict(),
                'source_info': source_info,
                'is_real_data': True,
                'has_mock_data': False,
                'columns': list(df.columns),
                'date_range': {
                    'start': df['date'].min().isoformat() if 'date' in df.columns else None,
                    'end': df['date'].max().isoformat() if 'date' in df.columns else None,
                }
            }

            logger.info(f"âœ“ {name}: æˆåŠŸæ”¶é›† {len(df)} æ¢çœŸå¯¦æ•¸æ“š")
            logger.info(f"  - è³ªé‡åˆ†æ•¸: {quality_report.overall_score:.2f}")
            logger.info(f"  - çœŸå¯¦æ€§ç¢ºèª: {'æ˜¯' if quality_report.is_real_data else 'å¦'}")

            return result

    def generate_collection_report(self, results: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆæ”¶é›†å ±å‘Š
        """
        report = []
        report.append("â•”" + "â•" * 78 + "â•—")
        report.append("â•‘" + " " * 20 + "çœŸå¯¦æ•¸æ“šæ”¶é›†å ±å‘Š" + " " * 35 + "â•‘")
        report.append("â•š" + "â•" * 78 + "â•")
        report.append("")

        # åŸºæœ¬ä¿¡æ¯
        report.append(f"ğŸ“… æ”¶é›†æ™‚é–“: {results['collection_time']}")
        report.append(f"ğŸ“Š æ™‚é–“ç¯„åœ: {results['start_date']} åˆ° {results['end_date']}")
        report.append(f"ğŸ”¢ é©é…å™¨æ•¸é‡: {results['adapters_count']}")
        report.append("")

        # æ”¶é›†çµæœ
        report.append("ğŸ“ˆ æ”¶é›†çµæœ:")
        report.append(f"  âœ“ æˆåŠŸ: {results['successful_collections']}/{results['adapters_count']}")
        report.append(f"  âœ— å¤±æ•—: {results['failed_collections']}")
        report.append(f"  ğŸš« æ‹’çµ• mock æ•¸æ“š: {results['mock_data_rejected']}")
        report.append(f"  âœ… ç¢ºèªçœŸå¯¦æ•¸æ“š: {results['real_data_confirmed']} æ¢è¨˜éŒ„")
        report.append("")

        # è©³ç´°çµæœ
        report.append("ğŸ“‹ è©³ç´°çµæœ:")
        for name, source_data in results['data_sources'].items():
            status = "âœ…" if source_data['success'] else "âŒ"
            report.append(f"  {status} {name}:")
            report.append(f"    - è¨˜éŒ„æ•¸é‡: {source_data['records_count']}")
            report.append(f"    - çœŸå¯¦æ•¸æ“š: {source_data['real_data_count']}")
            report.append(f"    - è³ªé‡åˆ†æ•¸: {source_data['quality_report']['overall_score']:.2f}")
            report.append(f"    - æ•¸æ“šæ–‡ä»¶: {source_data['data_file']}")

        # éŒ¯èª¤åˆ—è¡¨
        if results['errors']:
            report.append("")
            report.append("âš ï¸ éŒ¯èª¤åˆ—è¡¨:")
            for error in results['errors']:
                report.append(f"  - {error}")

        # æ•¸æ“šè³ªé‡è©•ä¼°
        report.append("")
        report.append("ğŸ“Š æ•¸æ“šè³ªé‡è©•ä¼°:")
        if results['mock_data_rejected'] == 0:
            report.append("  âœ… æ‰€æœ‰æ•¸æ“šå‡ç‚ºçœŸå¯¦æ•¸æ“š")
            report.append("  âœ… ç„¡ mock æ•¸æ“šæª¢æ¸¬")
            report.append("  âœ… æ•¸æ“šè³ªé‡å¯æ¥å—")
        else:
            report.append("  âš ï¸ ç™¼ç¾ mock æ•¸æ“šå˜—è©¦")
            report.append("  âš ï¸ æ•¸æ“šè³ªé‡å­˜åœ¨é¢¨éšª")

        report.append("")
        report.append("â•" * 80)
        report.append("æ³¨æ„: æ­¤ç³»çµ±åƒ…è™•ç†çœŸå¯¦æ•¸æ“šï¼Œæ‰€æœ‰ mock æ•¸æ“šéƒ½æœƒè¢«æ‹’çµ•")
        report.append("â•" * 80)

        return "\n".join(report)

    async def validate_real_data_only(self, results: Dict[str, Any]) -> bool:
        """
        é©—è­‰æ‰€æœ‰æ”¶é›†çš„æ•¸æ“šéƒ½æ˜¯çœŸå¯¦çš„
        """
        logger.info("æ­£åœ¨é©—è­‰æ•¸æ“šçœŸå¯¦æ€§...")

        # æª¢æŸ¥æ˜¯å¦æœ‰ mock æ•¸æ“šè¢«æ‹’çµ•
        if results['mock_data_rejected'] > 0:
            logger.error("é©—è­‰å¤±æ•—: æª¢æ¸¬åˆ° mock æ•¸æ“šå˜—è©¦")
            return False

        # æª¢æŸ¥æ¯å€‹æ•¸æ“šæº
        for name, source_data in results['data_sources'].items():
            if not source_data.get('is_real_data', False):
                logger.error(f"é©—è­‰å¤±æ•—: {name} æ•¸æ“šä¸æ˜¯çœŸå¯¦çš„")
                return False

            if source_data.get('has_mock_data', False):
                logger.error(f"é©—è­‰å¤±æ•—: {name} åŒ…å« mock æ•¸æ“š")
                return False

            # æª¢æŸ¥è³ªé‡å ±å‘Š
            quality_report = source_data.get('quality_report', {})
            if not quality_report.get('is_real_data', False):
                logger.error(f"é©—è­‰å¤±æ•—: {name} è³ªé‡å ±å‘Šé¡¯ç¤ºéçœŸå¯¦æ•¸æ“š")
                return False

        logger.info("âœ… æ‰€æœ‰æ•¸æ“šé©—è­‰é€šéï¼Œç¢ºèªç‚ºçœŸå¯¦æ•¸æ“š")
        return True

    def save_collection_results(self, results: Dict[str, Any], report_text: str) -> str:
        """
        ä¿å­˜æ”¶é›†çµæœ
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ä¿å­˜çµæœ JSON
        results_file = Path("gov_crawler/data/real_data_collection_results.json")
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)

        # ä¿å­˜å ±å‘Š
        report_file = Path(f"gov_crawler/data/real_data_collection_report_{timestamp}.txt")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_text)

        logger.info(f"çµæœå·²ä¿å­˜åˆ°: {results_file}")
        logger.info(f"å ±å‘Šå·²ä¿å­˜åˆ°: {report_file}")

        return str(report_file)

    def disable_mock_data_mode(self):
        """
        ç¦ç”¨ mock æ•¸æ“šæ¨¡å¼ - å¼·åˆ¶ä½¿ç”¨çœŸå¯¦æ•¸æ“š
        """
        logger.warning("=" * 80)
        logger.warning("ğŸš¨ MOCK æ•¸æ“šæ¨¡å¼å·²ç¦ç”¨")
        logger.warning("=" * 80)
        logger.warning("æ­¤ç³»çµ±åƒ…æ¥å—çœŸå¯¦æ•¸æ“šæºï¼Œä»»ä½• mock æ•¸æ“šå°‡è¢«æ‹’çµ•")
        logger.warning("é•è¦è¡Œç‚ºå°‡è¢«è¨˜éŒ„ä¸¦å°è‡´æ”¶é›†å¤±æ•—")
        logger.warning("=" * 80)

async def main():
    """ä¸»å‡½æ•¸"""
    print("\n" + "=" * 80)
    print("ğŸ”´ æ¸¯è‚¡é‡åŒ–äº¤æ˜“ç³»çµ± - çœŸå¯¦æ•¸æ“šæ”¶é›†å™¨")
    print("=" * 80)
    print("âš ï¸  è­¦å‘Š: æ­¤ç³»çµ±åƒ…è™•ç†çœŸå¯¦æ•¸æ“š")
    print("ğŸš« ç¦æ­¢ä½¿ç”¨ä»»ä½• mock æ•¸æ“š")
    print("âœ… åƒ…å¾å®˜æ–¹æ•¸æ“šæºæ”¶é›†æ•¸æ“š")
    print("=" * 80 + "\n")

    # å‰µå»ºæ”¶é›†å™¨
    collector = RealDataOnlyCollector()

    # ç¦ç”¨ mock æ•¸æ“šæ¨¡å¼
    collector.disable_mock_data_mode()

    # è¨­å®šæ”¶é›†æ™‚é–“ç¯„åœ
    end_date = datetime.now().strftime('%Y-%m-%d')
    start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')

    try:
        # æ”¶é›†çœŸå¯¦æ•¸æ“š
        results = await collector.collect_all_real_data(start_date, end_date)

        # é©—è­‰çœŸå¯¦æ•¸æ“š
        validation_passed = await collector.validate_real_data_only(results)

        if not validation_passed:
            logger.error("âŒ æ•¸æ“šé©—è­‰å¤±æ•— - å­˜åœ¨ mock æ•¸æ“š")
            return False

        # ç”Ÿæˆå ±å‘Š
        report_text = collector.generate_collection_report(results)
        print("\n" + report_text)

        # ä¿å­˜çµæœ
        report_file = collector.save_collection_results(results, report_text)

        # è¿”å›æˆåŠŸ
        logger.info(f"\nâœ… çœŸå¯¦æ•¸æ“šæ”¶é›†æˆåŠŸå®Œæˆ")
        logger.info(f"ğŸ“Š æ”¶é›†äº† {results['real_data_confirmed']} æ¢çœŸå¯¦æ•¸æ“šè¨˜éŒ„")
        logger.info(f"ğŸ“ å ±å‘Šæ–‡ä»¶: {report_file}")

        return True

    except MockDataError as e:
        logger.error(f"ğŸš« Mock æ•¸æ“šéŒ¯èª¤: {str(e)}")
        logger.error("æ”¶é›†å¤±æ•— - æ‹’çµ•ä½¿ç”¨ mock æ•¸æ“š")
        return False

    except Exception as e:
        logger.error(f"âŒ æ”¶é›†å¤±æ•—: {str(e)}")
        logger.error("è«‹æª¢æŸ¥æ•¸æ“šæºé€£æ¥å’Œé…ç½®")
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
