#!/usr/bin/env python3
"""
ç‰©æ¥­æ•¸æ“šçµ±ä¸€æ”¶é›†å™¨ - Property Data Collector
æ•´åˆå¤šå€‹ç‰©æ¥­æ•¸æ“šæºçš„çµ±ä¸€æ”¶é›†å™¨
åƒ…ä½¿ç”¨çœŸå¯¦æ•¸æ“šï¼Œçµ•å°ç¦æ­¢ mock æ•¸æ“š
"""

import asyncio
import logging
from typing import Dict, List, Any, Optional
import pandas as pd
from datetime import datetime, timedelta

from .landreg_property_adapter import LandRegPropertyAdapter
from .property_market_index_adapter import PropertyMarketIndexAdapter
from ..base_real_adapter import DataQualityReport, MockDataError

logger = logging.getLogger(__name__)

class PropertyDataCollector:
    """
    ç‰©æ¥­æ•¸æ“šçµ±ä¸€æ”¶é›†å™¨
    å”èª¿å¤šå€‹ç‰©æ¥­æ•¸æ“šé©é…å™¨ï¼Œç¢ºä¿åƒ…æ”¶é›†çœŸå¯¦æ•¸æ“š
    """

    def __init__(self):
        self.adapters = {}
        self._initialize_adapters()

    def _initialize_adapters(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç‰©æ¥­æ•¸æ“šé©é…å™¨"""
        logger.info("åˆå§‹åŒ–ç‰©æ¥­æ•¸æ“šé©é…å™¨...")

        self.adapters = {
            'land_registry': LandRegPropertyAdapter(),
            'market_index': PropertyMarketIndexAdapter(),
        }

        # è¨˜éŒ„åˆå§‹åŒ–è­¦å‘Š
        for name, adapter in self.adapters.items():
            adapter.log_real_data_warning()

        logger.info(f"å·²åˆå§‹åŒ– {len(self.adapters)} å€‹ç‰©æ¥­æ•¸æ“šé©é…å™¨")

    async def collect_all_property_data(self, start_date: str, end_date: str) -> Dict[str, Any]:
        """
        æ”¶é›†æ‰€æœ‰ç‰©æ¥­æ•¸æ“š
        """
        logger.warning("=" * 80)
        logger.warning("é–‹å§‹æ”¶é›†ç‰©æ¥­æ•¸æ“š - åš´æ ¼ç¦æ­¢ mock æ•¸æ“š")
        logger.warning("=" * 80)

        results = {
            'collection_time': datetime.now().isoformat(),
            'start_date': start_date,
            'end_date': end_date,
            'adapters_count': len(self.adapters),
            'successful_collections': 0,
            'failed_collections': 0,
            'total_records': 0,
            'real_data_confirmed': 0,
            'mock_data_rejected': 0,
            'data_sources': {},
            'quality_reports': {},
            'errors': []
        }

        for name, adapter in self.adapters.items():
            try:
                logger.info(f"\næ­£åœ¨æ”¶é›† {name} ç‰©æ¥­æ•¸æ“š...")
                result = await self._collect_from_adapter(adapter, name, start_date, end_date)
                results['data_sources'][name] = result
                results['successful_collections'] += 1
                results['total_records'] += len(result.get('data', []))
                results['real_data_confirmed'] += result.get('real_data_count', 0)

            except MockDataError as e:
                logger.error(f"ğŸš« {name}: Mock æ•¸æ“šéŒ¯èª¤ - {str(e)}")
                results['mock_data_rejected'] += 1
                results['errors'].append(f"{name}: {str(e)}")

            except Exception as e:
                logger.error(f"âŒ {name}: æ”¶é›†å¤±æ•— - {str(e)}")
                results['failed_collections'] += 1
                results['errors'].append(f"{name}: {str(e)}")

        # é©—è­‰ç¸½é«”æ•¸æ“šè³ªé‡
        if results['mock_data_rejected'] > 0:
            logger.error("ğŸš¨ æª¢æ¸¬åˆ° mock æ•¸æ“šå˜—è©¦ï¼å·²æ‹’çµ•æ‰€æœ‰ mock æ•¸æ“š")

        logger.info("\n" + "=" * 80)
        logger.info("ç‰©æ¥­æ•¸æ“šæ”¶é›†å®Œæˆ")
        logger.info(f"æˆåŠŸ: {results['successful_collections']}/{len(self.adapters)}")
        logger.info(f"å¤±æ•—: {results['failed_collections']}")
        logger.info(f"æ‹’çµ• mock æ•¸æ“š: {results['mock_data_rejected']}")
        logger.info(f"ç¢ºèªçœŸå¯¦æ•¸æ“š: {results['real_data_confirmed']} æ¢è¨˜éŒ„")
        logger.info("=" * 80)

        return results

    async def _collect_from_adapter(self, adapter, name: str, start_date: str, end_date: str) -> Dict[str, Any]:
        """
        å¾å–®å€‹é©é…å™¨æ”¶é›†æ•¸æ“š
        """
        async with adapter:
            # æ¸¬è©¦é€£æ¥
            connection_ok = await adapter.test_connection()
            if not connection_ok:
                raise ConnectionError(f"ç„¡æ³•é€£æ¥åˆ° {name} æ•¸æ“šæº")

            # ç²å–çœŸå¯¦æ•¸æ“š
            df, quality_report = await adapter.collect_and_validate(start_date, end_date)

            if df.empty:
                raise ValueError(f"{name}: æœªç²å–åˆ°ä»»ä½•æ•¸æ“š")

            # å¼·åˆ¶é©—è­‰çœŸå¯¦æ•¸æ“š
            is_real = await adapter.validate_data_is_real(df)
            if not is_real:
                raise MockDataError(f"{name}: æ•¸æ“šé©—è­‰å¤±æ•— - å¯èƒ½åŒ…å« mock æ•¸æ“š")

            # ä¿å­˜æ•¸æ“š
            saved_file = adapter.save_data_with_quality(df, quality_report)

            # ç²å–æ•¸æ“šæºä¿¡æ¯
            source_info = adapter.get_data_source_info()

            result = {
                'name': name,
                'success': True,
                'records_count': len(df),
                'real_data_count': len(df),
                'data_file': saved_file,
                'quality_report': quality_report.to_dict(),
                'source_info': source_info,
                'is_real_data': True,
                'has_mock_data': False,
                'columns': list(df.columns),
                'date_range': {
                    'start': df['date'].min().isoformat() if 'date' in df.columns and not df['date'].empty else None,
                    'end': df['date'].max().isoformat() if 'date' in df.columns and not df['date'].empty else None,
                },
                'supported_indicators': adapter.get_supported_indicators() if hasattr(adapter, 'get_supported_indicators') else []
            }

            logger.info(f"âœ“ {name}: æˆåŠŸæ”¶é›† {len(df)} æ¢çœŸå¯¦ç‰©æ¥­æ•¸æ“š")
            logger.info(f"  - è³ªé‡åˆ†æ•¸: {quality_report.overall_score:.2f}")
            logger.info(f"  - çœŸå¯¦æ€§ç¢ºèª: {'æ˜¯' if quality_report.is_real_data else 'å¦'}")

            return result

    def get_property_summary(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        ç²å–ç‰©æ¥­æ•¸æ“šæ‘˜è¦
        """
        if df.empty:
            return {"error": "No data available"}

        summary = {
            'total_records': len(df),
            'date_range': {
                'start': df['date'].min() if 'date' in df.columns else None,
                'end': df['date'].max() if 'date' in df.columns else None,
            },
            'indicators': df['indicator'].unique().tolist() if 'indicator' in df.columns else [],
            'sources': df['source'].unique().tolist() if 'source' in df.columns else [],
            'data_quality': {
                'real_data_percentage': (df['is_real'].sum() / len(df) * 100) if 'is_real' in df.columns else 100,
                'missing_values': df.isnull().sum().sum(),
                'completeness': (1 - df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100
            }
        }

        # åƒ¹æ ¼çµ±è¨ˆ
        if 'value' in df.columns:
            values = df['value'].dropna()
            if len(values) > 0:
                summary['price_statistics'] = {
                    'min': float(values.min()),
                    'max': float(values.max()),
                    'mean': float(values.mean()),
                    'median': float(values.median()),
                    'std': float(values.std())
                }

        # äº¤æ˜“é‡çµ±è¨ˆ
        if 'transaction' in df['indicator'].str.lower().any() if 'indicator' in df.columns else False:
            transaction_data = df[df['indicator'].str.contains('Transaction', case=False, na=False) if 'indicator' in df.columns else False]
            if not transaction_data.empty and 'value' in transaction_data.columns:
                summary['transaction_statistics'] = {
                    'total_transactions': int(transaction_data['value'].sum()),
                    'average_monthly': float(transaction_data['value'].mean())
                }

        # åœ°å€åˆ†æ
        if 'district' in df.columns:
            district_counts = df['district'].value_counts().to_dict()
            summary['district_distribution'] = district_counts

        return summary

    def generate_property_report(self, results: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆç‰©æ¥­æ•¸æ“šå ±å‘Š
        """
        report = []
        report.append("â•”" + "â•" * 78 + "â•—")
        report.append("â•‘" + " " * 24 + "ç‰©æ¥­æ•¸æ“šæ”¶é›†å ±å‘Š" + " " * 35 + "â•‘")
        report.append("â•š" + "â•" * 78 + "â•")
        report.append("")

        # åŸºæœ¬ä¿¡æ¯
        report.append(f"ğŸ“… æ”¶é›†æ™‚é–“: {results['collection_time']}")
        report.append(f"ğŸ“Š æ™‚é–“ç¯„åœ: {results['start_date']} åˆ° {results['end_date']}")
        report.append(f"ğŸ”¢ é©é…å™¨æ•¸é‡: {results['adapters_count']}")
        report.append("")

        # æ”¶é›†çµæœ
        report.append("ğŸ“ˆ æ”¶é›†çµæœ:")
        report.append(f"  âœ“ æˆåŠŸ: {results['successful_collections']}/{results['adapters_count']}")
        report.append(f"  âœ— å¤±æ•—: {results['failed_collections']}")
        report.append(f"  ğŸš« æ‹’çµ• mock æ•¸æ“š: {results['mock_data_rejected']}")
        report.append(f"  âœ… ç¢ºèªçœŸå¯¦æ•¸æ“š: {results['real_data_confirmed']} æ¢è¨˜éŒ„")
        report.append("")

        # è©³ç´°çµæœ
        report.append("ğŸ“‹ è©³ç´°çµæœ:")
        for name, source_data in results['data_sources'].items():
            status = "âœ…" if source_data['success'] else "âŒ"
            report.append(f"  {status} {name}:")
            report.append(f"    - è¨˜éŒ„æ•¸é‡: {source_data['records_count']}")
            report.append(f"    - çœŸå¯¦æ•¸æ“š: {source_data['real_data_count']}")
            report.append(f"    - è³ªé‡åˆ†æ•¸: {source_data['quality_report']['overall_score']:.2f}")
            if source_data.get('supported_indicators'):
                report.append(f"    - æ”¯æŒæŒ‡æ¨™: {len(source_data['supported_indicators'])} å€‹")
            report.append(f"    - æ•¸æ“šæ–‡ä»¶: {source_data['data_file']}")

        # éŒ¯èª¤åˆ—è¡¨
        if results['errors']:
            report.append("")
            report.append("âš ï¸ éŒ¯èª¤åˆ—è¡¨:")
            for error in results['errors']:
                report.append(f"  - {error}")

        # æ•¸æ“šè³ªé‡è©•ä¼°
        report.append("")
        report.append("ğŸ“Š æ•¸æ“šè³ªé‡è©•ä¼°:")
        if results['mock_data_rejected'] == 0:
            report.append("  âœ… æ‰€æœ‰æ•¸æ“šå‡ç‚ºçœŸå¯¦æ•¸æ“š")
            report.append("  âœ… ç„¡ mock æ•¸æ“šæª¢æ¸¬")
            report.append("  âœ… æ•¸æ“šè³ªé‡å¯æ¥å—")
        else:
            report.append("  âš ï¸ ç™¼ç¾ mock æ•¸æ“šå˜—è©¦")
            report.append("  âš ï¸ æ•¸æ“šè³ªé‡å­˜åœ¨é¢¨éšª")

        report.append("")
        report.append("ğŸ  ç‰©æ¥­æ•¸æ“šé¡å‹:")
        report.append("  â€¢ åœŸåœ°è¨»å†Šè™•äº¤æ˜“æ•¸æ“š")
        report.append("  â€¢ ç‰©æ¥­åƒ¹æ ¼æŒ‡æ•¸ (CCL, RVD)")
        report.append("  â€¢ åœ°å€å¸‚å ´åˆ†æ")
        report.append("  â€¢ é¢ç©åˆ†å¸ƒçµ±è¨ˆ")
        report.append("  â€¢ ç§Ÿé‡‘æŒ‡æ•¸")

        report.append("")
        report.append("â•" * 80)
        report.append("æ³¨æ„: æ­¤ç³»çµ±åƒ…è™•ç†çœŸå¯¦ç‰©æ¥­æ•¸æ“šï¼Œæ‰€æœ‰ mock æ•¸æ“šéƒ½æœƒè¢«æ‹’çµ•")
        report.append("â•" * 80)

        return "\n".join(report)

    async def validate_property_data_only(self, results: Dict[str, Any]) -> bool:
        """
        é©—è­‰æ‰€æœ‰æ”¶é›†çš„æ•¸æ“šéƒ½æ˜¯çœŸå¯¦çš„
        """
        logger.info("æ­£åœ¨é©—è­‰ç‰©æ¥­æ•¸æ“šçœŸå¯¦æ€§...")

        # æª¢æŸ¥æ˜¯å¦æœ‰ mock æ•¸æ“šè¢«æ‹’çµ•
        if results['mock_data_rejected'] > 0:
            logger.error("é©—è­‰å¤±æ•—: æª¢æ¸¬åˆ° mock æ•¸æ“šå˜—è©¦")
            return False

        # æª¢æŸ¥æ¯å€‹æ•¸æ“šæº
        for name, source_data in results['data_sources'].items():
            if not source_data.get('is_real_data', False):
                logger.error(f"é©—è­‰å¤±æ•—: {name} æ•¸æ“šä¸æ˜¯çœŸå¯¦çš„")
                return False

            if source_data.get('has_mock_data', False):
                logger.error(f"é©—è­‰å¤±æ•—: {name} åŒ…å« mock æ•¸æ“š")
                return False

        logger.info("âœ… æ‰€æœ‰ç‰©æ¥­æ•¸æ“šé©—è­‰é€šéï¼Œç¢ºèªç‚ºçœŸå¯¦æ•¸æ“š")
        return True

    def save_collection_results(self, results: Dict[str, Any], report_text: str) -> str:
        """
        ä¿å­˜æ”¶é›†çµæœ
        """
        import json
        from pathlib import Path

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ä¿å­˜çµæœ JSON
        results_file = Path("gov_crawler/data/property_data_collection_results.json")
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)

        # ä¿å­˜å ±å‘Š
        report_file = Path(f"gov_crawler/data/property_data_collection_report_{timestamp}.txt")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_text)

        logger.info(f"çµæœå·²ä¿å­˜åˆ°: {results_file}")
        logger.info(f"å ±å‘Šå·²ä¿å­˜åˆ°: {report_file}")

        return str(report_file)

async def main():
    """ä¸»å‡½æ•¸ - æ¸¬è©¦ç‰©æ¥­æ•¸æ“šæ”¶é›†"""
    print("\n" + "=" * 80)
    print("ğŸ  æ¸¯è‚¡é‡åŒ–ç³»çµ± - ç‰©æ¥­æ•¸æ“šæ”¶é›†å™¨")
    print("=" * 80)
    print("âš ï¸  æ­¤ç³»çµ±åƒ…è™•ç†çœŸå¯¦ç‰©æ¥­æ•¸æ“š")
    print("ğŸš« åš´æ ¼ç¦æ­¢ä½¿ç”¨ä»»ä½• mock æ•¸æ“š")
    print("âœ… æ‰€æœ‰æ•¸æ“šä¾†è‡ªå®˜æ–¹æ•¸æ“šæº")
    print("=" * 80 + "\n")

    collector = PropertyDataCollector()

    end_date = datetime.now().strftime('%Y-%m-%d')
    start_date = (datetime.now() - timedelta(days=90)).strftime('%Y-%m-%d')

    try:
        results = await collector.collect_all_property_data(start_date, end_date)

        validation_passed = await collector.validate_property_data_only(results)

        if validation_passed:
            print("\nâœ… æ•¸æ“šé©—è­‰é€šé - æ‰€æœ‰æ•¸æ“šå‡ç‚ºçœŸå¯¦ç‰©æ¥­æ•¸æ“š")
        else:
            print("\nâŒ æ•¸æ“šé©—è­‰å¤±æ•— - å¯èƒ½å­˜åœ¨ mock æ•¸æ“š")

        report_text = collector.generate_property_report(results)
        print("\n" + report_text)

        report_file = collector.save_collection_results(results, report_text)

        print(f"\nâœ… ç‰©æ¥­æ•¸æ“šæ”¶é›†æˆåŠŸå®Œæˆ")
        print(f"ğŸ“Š æ”¶é›†äº† {results['real_data_confirmed']} æ¢çœŸå¯¦æ•¸æ“šè¨˜éŒ„")
        print(f"ğŸ“ å ±å‘Šæ–‡ä»¶: {report_file}")

        return True

    except MockDataError as e:
        print(f"\nğŸš« Mock æ•¸æ“šéŒ¯èª¤: {str(e)}")
        print("æ”¶é›†å¤±æ•— - æ‹’çµ•ä½¿ç”¨ mock æ•¸æ“š")
        return False

    except Exception as e:
        print(f"\nâŒ æ”¶é›†å¤±æ•—: {str(e)}")
        return False

if __name__ == "__main__":
    import sys
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
