#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ—¥å¿—è½®è½¬å’Œå½’æ¡£ç³»ç»Ÿ
æ”¯æŒè‡ªåŠ¨è½®è½¬ã€å‹ç¼©ã€å½’æ¡£å’Œæ¸…ç†åŠŸèƒ½
"""

import os
import sys
import time
import gzip
import shutil
import logging
import logging.handlers
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional, List, Dict
import threading
from dataclasses import dataclass

@dataclass
class LogRotationConfig:
    """æ—¥å¿—è½®è½¬é…ç½®"""
    max_size: int = 100 * 1024 * 1024  # 100MB
    backup_count: int = 10
    compression: bool = True
    archive_after_days: int = 30
    delete_after_days: int = 365
    archive_dir: str = "logs/archive"
    compress_format: str = "gzip"  # gzip, bzip2
    utc_timestamp: bool = True

class AdvancedRotatingFileHandler(logging.handlers.BaseRotatingHandler):
    """é«˜çº§è½®è½¬æ–‡ä»¶å¤„ç†å™¨"""

    def __init__(self, filename: str, mode: str = 'a', encoding: str = None,
                 delay: bool = False, errors: str = None,
                 config: Optional[LogRotationConfig] = None):
        self.config = config or LogRotationConfig()
        self.archive_lock = threading.Lock()

        super().__init__(filename, mode, encoding, delay, errors)

    def shouldRollover(self, record):
        """åˆ¤æ–­æ˜¯å¦éœ€è¦è½®è½¬"""
        if self.stream is None:
            self.stream = self._open()

        if self.config.max_size > 0 and os.path.exists(self.baseFilename):
            file_size = os.path.getsize(self.baseFilename)
            if file_size >= self.config.max_size:
                return 1

        return 0

    def doRollover(self):
        """æ‰§è¡Œè½®è½¬"""
        if self.stream:
            self.stream.close()
            self.stream = None

        # åˆ›å»ºæ—¶é—´æˆ³
        if self.config.utc_timestamp:
            timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')
        else:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶å
        dfn = self.rotation_filename(f"{self.baseFilename}.{timestamp}")
        self.rotate(self.baseFilename, dfn)

    def rotation_filename(self, default_name):
        """ç”Ÿæˆè½®è½¬æ–‡ä»¶å"""
        return default_name

    def rotate(self, source, dest):
        """è½®è½¬æ—¥å¿—æ–‡ä»¶"""
        with self.archive_lock:
            try:
                # ç§»åŠ¨æ–‡ä»¶
                if os.path.exists(source):
                    shutil.move(source, dest)
                    print(f"ğŸ“ æ—¥å¿—è½®è½¬: {source} -> {dest}")

                # å‹ç¼©ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if self.config.compression:
                    compressed_path = self._compress_file(dest)
                    if compressed_path:
                        os.remove(dest)  # åˆ é™¤æœªå‹ç¼©çš„æ–‡ä»¶
                        dest = compressed_path
                        print(f"ğŸ—œï¸  å‹ç¼©æ—¥å¿—: {dest}")

                # ç§»åŠ¨åˆ°å½’æ¡£ç›®å½•
                if self.config.archive_dir:
                    archive_path = self._archive_file(dest)
                    if archive_path:
                        os.remove(dest)  # åˆ é™¤åŸæ–‡ä»¶
                        print(f"ğŸ“¦ å½’æ¡£æ—¥å¿—: {archive_path}")

            except Exception as e:
                print(f"âŒ æ—¥å¿—è½®è½¬å¤±è´¥: {e}")
                raise

    def _compress_file(self, filepath: str) -> Optional[str]:
        """å‹ç¼©æ–‡ä»¶"""
        try:
            compressed_path = f"{filepath}.gz"

            with open(filepath, 'rb') as f_in:
                with gzip.open(compressed_path, 'wb') as f_out:
                    shutil.copyfileobj(f_in, f_out)

            print(f"âœ… æ–‡ä»¶å‹ç¼©æˆåŠŸ: {compressed_path}")
            return compressed_path

        except Exception as e:
            print(f"âŒ æ–‡ä»¶å‹ç¼©å¤±è´¥: {e}")
            return None

    def _archive_file(self, filepath: str) -> Optional[str]:
        """ç§»åŠ¨æ–‡ä»¶åˆ°å½’æ¡£ç›®å½•"""
        try:
            os.makedirs(self.config.archive_dir, exist_ok=True)

            filename = os.path.basename(filepath)
            timestamp = datetime.now().strftime('%Y%m%d')
            archive_filename = f"{timestamp}_{filename}"
            archive_path = os.path.join(self.config.archive_dir, archive_filename)

            # å¤„ç†æ–‡ä»¶åå†²çª
            counter = 1
            while os.path.exists(archive_path):
                base, ext = os.path.splitext(archive_filename)
                archive_filename = f"{base}_{counter}{ext}"
                archive_path = os.path.join(self.config.archive_dir, archive_filename)
                counter += 1

            shutil.move(filepath, archive_path)
            print(f"âœ… æ–‡ä»¶å½’æ¡£æˆåŠŸ: {archive_path}")
            return archive_path

        except Exception as e:
            print(f"âŒ æ–‡ä»¶å½’æ¡£å¤±è´¥: {e}")
            return None

class LogArchiver:
    """æ—¥å¿—å½’æ¡£å™¨"""

    def __init__(self, config: LogRotationConfig):
        self.config = config
        self.archive_thread = None
        self.running = False

    def start_background_archive(self):
        """å¯åŠ¨åå°å½’æ¡£ä»»åŠ¡"""
        if self.running:
            return

        self.running = True
        self.archive_thread = threading.Thread(target=self._archive_worker, daemon=True)
        self.archive_thread.start()
        print("ğŸ—‚ï¸  æ—¥å¿—å½’æ¡£ä»»åŠ¡å·²å¯åŠ¨")

    def stop_background_archive(self):
        """åœæ­¢åå°å½’æ¡£ä»»åŠ¡"""
        self.running = False
        if self.archive_thread:
            self.archive_thread.join()
        print("ğŸ›‘ æ—¥å¿—å½’æ¡£ä»»åŠ¡å·²åœæ­¢")

    def _archive_worker(self):
        """å½’æ¡£å·¥ä½œçº¿ç¨‹"""
        while self.running:
            try:
                self._archive_old_files()
                time.sleep(3600)  # æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡
            except Exception as e:
                print(f"âŒ å½’æ¡£ä»»åŠ¡å¼‚å¸¸: {e}")
                time.sleep(300)  # å‡ºé”™åç­‰å¾…5åˆ†é’Ÿå†è¯•

    def _archive_old_files(self):
        """å½’æ¡£æ—§æ–‡ä»¶"""
        if not self.config.archive_dir:
            return

        log_dir = Path(self.config.archive_dir).parent
        archive_dir = Path(self.config.archive_dir)

        # æ‰«æéœ€è¦å½’æ¡£çš„æ–‡ä»¶
        cutoff_date = datetime.now() - timedelta(days=self.config.archive_after_days)

        for log_file in log_dir.glob("*.log*"):
            if log_file.name.endswith(('.gz', '.bz2')):  # å·²å‹ç¼©
                continue

            file_time = datetime.fromtimestamp(log_file.stat().st_mtime)
            if file_time < cutoff_date:
                self._archive_single_file(log_file)

        # æ¸…ç†è¿‡æœŸæ–‡ä»¶
        self._cleanup_old_archives()

    def _archive_single_file(self, filepath: Path):
        """å½’æ¡£å•ä¸ªæ–‡ä»¶"""
        try:
            # å‹ç¼©æ–‡ä»¶
            if self.config.compression:
                compressed_path = self._compress_file(filepath)
                if compressed_path:
                    os.remove(filepath)
                    filepath = Path(compressed_path)

            # ç§»åŠ¨åˆ°å½’æ¡£ç›®å½•
            os.makedirs(self.config.archive_dir, exist_ok=True)
            archive_path = archive_dir / filepath.name

            counter = 1
            while archive_path.exists():
                base = filepath.stem
                ext = filepath.suffix
                archive_path = archive_dir / f"{base}_{counter}{ext}"
                counter += 1

            shutil.move(str(filepath), str(archive_path))
            print(f"ğŸ“¦ å·²å½’æ¡£: {archive_path}")

        except Exception as e:
            print(f"âŒ å½’æ¡£æ–‡ä»¶å¤±è´¥ {filepath}: {e}")

    def _compress_file(self, filepath: Path) -> Optional[str]:
        """å‹ç¼©æ–‡ä»¶"""
        try:
            compressed_path = f"{filepath}.gz"

            with open(filepath, 'rb') as f_in:
                with gzip.open(compressed_path, 'wb') as f_out:
                    shutil.copyfileobj(f_in, f_out)

            return compressed_path

        except Exception as e:
            print(f"âŒ å‹ç¼©æ–‡ä»¶å¤±è´¥ {filepath}: {e}")
            return None

    def _cleanup_old_archives(self):
        """æ¸…ç†è¿‡æœŸå½’æ¡£æ–‡ä»¶"""
        try:
            archive_dir = Path(self.config.archive_dir)
            if not archive_dir.exists():
                return

            cutoff_date = datetime.now() - timedelta(days=self.config.delete_after_days)

            for archive_file in archive_dir.glob("*"):
                if archive_file.is_file():
                    file_time = datetime.fromtimestamp(archive_file.stat().st_mtime)
                    if file_time < cutoff_date:
                        archive_file.unlink()
                        print(f"ğŸ—‘ï¸  å·²åˆ é™¤è¿‡æœŸå½’æ¡£: {archive_file}")

        except Exception as e:
            print(f"âŒ æ¸…ç†å½’æ¡£å¤±è´¥: {e}")

class LogRotationManager:
    """æ—¥å¿—è½®è½¬ç®¡ç†å™¨"""

    def __init__(self, config: Optional[LogRotationConfig] = None):
        self.config = config or LogRotationConfig()
        self.handlers: Dict[str, AdvancedRotatingFileHandler] = {}
        self.archiver = LogArchiver(self.config)
        self.logger = logging.getLogger(__name__)

    def setup_logger(self, name: str, log_file: str, level: int = logging.INFO,
                    formatter: Optional[logging.Formatter] = None) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""

        # åˆ›å»ºæ—¥å¿—ç›®å½•
        os.makedirs(os.path.dirname(log_file), exist_ok=True)

        # åˆ›å»ºè½®è½¬å¤„ç†å™¨
        handler = AdvancedRotatingFileHandler(
            log_file,
            config=self.config
        )

        # è®¾ç½®æ ¼å¼å™¨
        if formatter is None:
            formatter = logging.Formatter(
                fmt='%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s',
                datefmt='%Y-%m-%d %H:%M:%S'
            )

        handler.setFormatter(formatter)
        handler.setLevel(level)

        # åˆ›å»ºæˆ–è·å–è®°å½•å™¨
        logger = logging.getLogger(name)
        logger.setLevel(level)
        logger.addHandler(handler)

        # é¿å…é‡å¤æ·»åŠ å¤„ç†å™¨
        for existing_handler in logger.handlers[:]:
            if isinstance(existing_handler, AdvancedRotatingFileHandler):
                logger.removeHandler(existing_handler)

        logger.addHandler(handler)

        # ä¿å­˜å¤„ç†å™¨å¼•ç”¨
        self.handlers[name] = handler

        return logger

    def get_structured_logger(self, name: str, log_file: str) -> logging.Logger:
        """è·å–ç»“æ„åŒ–æ—¥å¿—è®°å½•å™¨"""
        formatter = logging.Formatter(
            fmt='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )

        return self.setup_logger(name, log_file, formatter=formatter)

    def start_archiving(self):
        """å¯åŠ¨å½’æ¡£åŠŸèƒ½"""
        self.archiver.start_background_archive()

    def stop_archiving(self):
        """åœæ­¢å½’æ¡£åŠŸèƒ½"""
        self.archiver.stop_background_archive()

    def get_log_stats(self) -> Dict:
        """è·å–æ—¥å¿—ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'active_handlers': len(self.handlers),
            'log_files': [],
            'archive_files': [],
            'total_size': 0
        }

        # ç»Ÿè®¡æ´»åŠ¨å¤„ç†å™¨
        for name, handler in self.handlers.items():
            if hasattr(handler, 'baseFilename'):
                log_file = handler.baseFilename
                file_size = os.path.getsize(log_file) if os.path.exists(log_file) else 0
                stats['log_files'].append({
                    'handler': name,
                    'file': log_file,
                    'size': file_size
                })
                stats['total_size'] += file_size

        # ç»Ÿè®¡å½’æ¡£æ–‡ä»¶
        if os.path.exists(self.config.archive_dir):
            for archive_file in Path(self.config.archive_dir).glob("*"):
                if archive_file.is_file():
                    file_size = archive_file.stat().st_size
                    stats['archive_files'].append({
                        'file': str(archive_file),
                        'size': file_size
                    })
                    stats['total_size'] += file_size

        return stats

    def cleanup_all(self):
        """æ¸…ç†æ‰€æœ‰æ—¥å¿—èµ„æº"""
        self.stop_archiving()

        for name, handler in self.handlers.items():
            try:
                handler.close()
                print(f"âœ… å·²å…³é—­æ—¥å¿—å¤„ç†å™¨: {name}")
            except Exception as e:
                print(f"âŒ å…³é—­æ—¥å¿—å¤„ç†å™¨å¤±è´¥ {name}: {e}")

        self.handlers.clear()

def create_app_logger(name: str, log_dir: str = "logs",
                     config: Optional[LogRotationConfig] = None) -> logging.Logger:
    """åˆ›å»ºåº”ç”¨ç¨‹åºæ—¥å¿—è®°å½•å™¨"""

    if config is None:
        config = LogRotationConfig(
            max_size=50 * 1024 * 1024,  # 50MB
            backup_count=5,
            compression=True,
            archive_after_days=7,
            delete_after_days=90,
            archive_dir=os.path.join(log_dir, "archive")
        )

    manager = LogRotationManager(config)
    log_file = os.path.join(log_dir, "app.log")

    # å¯åŠ¨å½’æ¡£
    manager.start_archiving()

    logger = manager.get_structured_logger(name, log_file)

    # æ·»åŠ åº”ç”¨ä¿¡æ¯
    logger.info(f"ğŸš€ æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    logger.info(f"ğŸ“ æ—¥å¿—ç›®å½•: {log_dir}")
    logger.info(f"ğŸ“¦ å½’æ¡£ç›®å½•: {config.archive_dir}")

    return logger

def create_trading_logger(name: str = "trading", log_dir: str = "logs") -> logging.Logger:
    """åˆ›å»ºäº¤æ˜“ä¸“ç”¨æ—¥å¿—è®°å½•å™¨"""

    config = LogRotationConfig(
        max_size=100 * 1024 * 1024,  # 100MB - äº¤æ˜“æ—¥å¿—å¯èƒ½è¾ƒå¤§
        backup_count=20,  # ä¿ç•™æ›´å¤šå¤‡ä»½
        compression=True,
        archive_after_days=3,  # æ›´é¢‘ç¹å½’æ¡£
        delete_after_days=180,  # ä¿ç•™æ›´é•¿æ—¶é—´
        archive_dir=os.path.join(log_dir, "trading_archive")
    )

    manager = LogRotationManager(config)
    log_file = os.path.join(log_dir, "trading.log")

    manager.start_archiving()
    logger = manager.get_structured_logger(name, log_file)

    logger.info(f"ğŸ“Š äº¤æ˜“æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

    return logger

def create_access_logger(name: str = "access", log_dir: str = "logs") -> logging.Logger:
    """åˆ›å»ºè®¿é—®æ—¥å¿—è®°å½•å™¨"""

    config = LogRotationConfig(
        max_size=200 * 1024 * 1024,  # 200MB - è®¿é—®æ—¥å¿—æœ€å¤§
        backup_count=30,
        compression=True,
        archive_after_days=2,
        delete_after_days=365,
        archive_dir=os.path.join(log_dir, "access_archive")
    )

    manager = LogRotationManager(config)
    log_file = os.path.join(log_dir, "access.log")

    manager.start_archiving()
    logger = manager.get_structured_logger(name, log_file)

    logger.info(f"ğŸŒ è®¿é—®æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

    return logger

# å…¨å±€æ—¥å¿—ç®¡ç†å™¨å®ä¾‹
_log_manager: Optional[LogRotationManager] = None

def get_global_logger() -> LogRotationManager:
    """è·å–å…¨å±€æ—¥å¿—ç®¡ç†å™¨"""
    global _log_manager
    if _log_manager is None:
        _log_manager = LogRotationManager()
    return _log_manager

def setup_production_logging():
    """è®¾ç½®ç”Ÿäº§ç¯å¢ƒæ—¥å¿—"""
    config = LogRotationConfig(
        max_size=200 * 1024 * 1024,  # 200MB
        backup_count=50,
        compression=True,
        archive_after_days=1,
        delete_after_days=365,
        archive_dir="logs/archive",
        utc_timestamp=True
    )

    manager = LogRotationManager(config)
    manager.start_archiving()

    # è®¾ç½®æ ¹æ—¥å¿—è®°å½•å™¨
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)

    # æ§åˆ¶å°å¤„ç†å™¨ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.WARNING)
    console_formatter = logging.Formatter(
        fmt='%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    console_handler.setFormatter(console_formatter)
    root_logger.addHandler(console_handler)

    # æ–‡ä»¶å¤„ç†å™¨ï¼ˆæ‰€æœ‰æ—¥å¿—ï¼‰
    log_file = "logs/app.log"
    app_handler = AdvancedRotatingFileHandler(log_file, config=config)
    app_handler.setLevel(logging.INFO)
    app_formatter = logging.Formatter(
        fmt='%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    app_handler.setFormatter(app_formatter)
    root_logger.addHandler(app_handler)

    print("ğŸ“‹ ç”Ÿäº§ç¯å¢ƒæ—¥å¿—ç³»ç»Ÿå·²åˆå§‹åŒ–")
    return manager

if __name__ == "__main__":
    # æµ‹è¯•æ—¥å¿—è½®è½¬ç³»ç»Ÿ
    print("ğŸ§ª æµ‹è¯•æ—¥å¿—è½®è½¬ç³»ç»Ÿ...")

    logger = create_app_logger("test", "logs")
    logger.info("æµ‹è¯•ä¿¡æ¯")
    logger.warning("æµ‹è¯•è­¦å‘Š")
    logger.error("æµ‹è¯•é”™è¯¯")

    # æ¨¡æ‹Ÿæ—¥å¿—å¢é•¿
    for i in range(1000):
        logger.info(f"æµ‹è¯•æ—¥å¿—æ¡ç›® {i}: " + "x" * 100)

    time.sleep(2)

    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    manager = get_global_logger()
    stats = manager.get_log_stats()
    print(f"\nğŸ“Š æ—¥å¿—ç»Ÿè®¡:")
    print(f"  æ´»è·ƒå¤„ç†å™¨: {stats['active_handlers']}")
    print(f"  æ€»å¤§å°: {stats['total_size'] / 1024 / 1024:.2f} MB")
    print(f"  æ—¥å¿—æ–‡ä»¶æ•°: {len(stats['log_files'])}")
    print(f"  å½’æ¡£æ–‡ä»¶æ•°: {len(stats['archive_files'])}")

    # æ¸…ç†
    manager.cleanup_all()
    print("\nâœ… æ—¥å¿—è½®è½¬ç³»ç»Ÿæµ‹è¯•å®Œæˆ")
