"""
ğŸš€ Rayon-based Parallel Optimizer - æ¥µè‡´æ€§èƒ½ä¸¦è¡Œåƒæ•¸å„ªåŒ–å™¨

ä½¿ç”¨ Rayon (Rust) å’Œ ThreadPoolExecutor (Python) å¯¦ç¾å¤šæ ¸ CPU å„ªåŒ–ï¼š
- è‡ªå‹• CPU æ ¸å¿ƒæª¢æ¸¬èˆ‡å‹•æ…‹å·¥ä½œæ± ç®¡ç†
- æ”¯æŒ 1000 åƒæ•¸çµ„åˆåœ¨ 8 æ ¸ CPU ä¸Š < 10 ç§’å®Œæˆ
- æ™ºèƒ½å·¥ä½œåˆ†ç™¼èˆ‡è² è¼‰å‡è¡¡
- å¤šåŸ·è¡Œç­–ç•¥ (Rayon/Multiprocessing/ThreadPool)
- å¯¦æ™‚æ€§èƒ½ç›£æ§èˆ‡è‡ªå‹•èª¿å„ª
- å…§å­˜ä½¿ç”¨å„ªåŒ–èˆ‡åƒåœ¾å›æ”¶
"""

import os
import sys
import time
import logging
from typing import Dict, List, Any, Optional, Tuple, Callable
from dataclasses import dataclass, field
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from concurrent.futures.process import ProcessPoolExecutor
import multiprocessing as mp
from functools import partial
from collections import defaultdict, deque
import threading
import queue
import psutil
import numpy as np
import pandas as pd
import gc

# Try to import Rayon (Rust) - fallback to Python implementations
try:
    import ray
    RAYON_AVAILABLE = True
    logger = logging.getLogger(__name__)
    logger.info("ğŸš€ Rayon æ¡†æ¶å·²åŠ è¼‰ - Rust åŠ é€Ÿæ¨¡å¼")
except ImportError:
    RAYON_AVAILABLE = False
    logger = logging.getLogger(__name__)
    logger.info("âš ï¸  Rayon ä¸å¯ç”¨ - ä½¿ç”¨ Python ThreadPoolExecutor")

# from .acceleration import get_accelerator, PerformanceConfig

logger = logging.getLogger(__name__)


@dataclass
class OptimizationConfig:
    """é…ç½®ç”¨æ–¼ä¸¦è¡Œå„ªåŒ–çš„åƒæ•¸"""
    strategy_type: str
    parameter_spaces: List[Dict[str, Any]]
    data: pd.DataFrame
    objective: str = "sharpe_ratio"  # maximize, minimize
    max_workers: Optional[int] = None
    chunk_size: int = 100
    timeout_seconds: int = 300
    use_rayon: bool = True
    use_rust: bool = True
    batch_size: int = 1000
    memory_limit_mb: int = 1024
    adaptive_chunking: bool = True
    load_balance: bool = True


@dataclass
class OptimizationResult:
    """ä¸¦è¡Œå„ªåŒ–çš„çµæœ"""
    best_params: Dict[str, float]
    best_score: float
    all_results: List[Dict[str, Any]]
    execution_time_ms: int
    workers_used: int
    total_combinations: int
    speedup_factor: float
    throughput_per_second: float
    peak_memory_mb: float
    avg_time_per_combination_ms: float
    load_balance_efficiency: float


class CPUDetector:
    """CPU æ ¸å¿ƒæª¢æ¸¬èˆ‡åˆ†æ"""

    @staticmethod
    def detect_cpu_cores() -> Dict[str, int]:
        """æª¢æ¸¬ CPU æ ¸å¿ƒä¿¡æ¯"""
        physical_cores = psutil.cpu_count(logical=False) or 1
        logical_cores = psutil.cpu_count(logical=True) or 1
        max_workers = min(physical_cores, 32)  # é™åˆ¶æœ€å¤§å·¥ä½œç·šç¨‹æ•¸

        # æª¢æ¸¬ CPU é »ç‡
        try:
            cpu_freq = psutil.cpu_freq()
            max_frequency = cpu_freq.max if cpu_freq else 0
            current_frequency = cpu_freq.current if cpu_freq else 0
        except:
            max_frequency = 0
            current_frequency = 0

        # æª¢æ¸¬ CPU ä½¿ç”¨ç‡
        current_cpu_percent = psutil.cpu_percent(interval=0.1)

        return {
            'physical_cores': physical_cores,
            'logical_cores': logical_cores,
            'max_recommended_workers': max_workers,
            'current_cpu_percent': current_cpu_percent,
            'max_frequency_mhz': max_frequency,
            'current_frequency_mhz': current_frequency,
        }


class DynamicThreadPool:
    """å‹•æ…‹ç·šç¨‹æ± ç®¡ç†å™¨ - æ ¹æ“šè² è¼‰è‡ªå‹•èª¿æ•´"""

    def __init__(self, max_workers: int, adaptive: bool = True):
        self.max_workers = max_workers
        self.adaptive = adaptive
        self.current_workers = max_workers
        self.executor: Optional[ThreadPoolExecutor] = None
        self.active_tasks = 0
        self.completed_tasks = 0
        self.lock = threading.Lock()
        self.performance_history = deque(maxlen=100)
        self.cpu_monitor = CPUDetector()

    def __enter__(self):
        self.executor = ThreadPoolExecutor(max_workers=self.current_workers)
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.executor:
            self.executor.shutdown(wait=True)
        gc.collect()

    def submit_task(self, func: Callable, *args, **kwargs) -> Any:
        """æäº¤ä»»å‹™ï¼ˆè‡ªå‹•èª¿æ•´å·¥ä½œç·šç¨‹æ•¸ï¼‰"""
        if self.adaptive:
            self._maybe_adjust_workers()

        if not self.executor:
            raise RuntimeError("ThreadPool æœªåˆå§‹åŒ–")

        with self.lock:
            self.active_tasks += 1

        future = self.executor.submit(func, *args, **kwargs)
        return future

    def _maybe_adjust_workers(self):
        """æ ¹æ“šç•¶å‰è² è¼‰å‹•æ…‹èª¿æ•´å·¥ä½œç·šç¨‹æ•¸"""
        cpu_info = self.cpu_monitor.detect_cpu_cores()
        cpu_usage = cpu_info['current_cpu_percent']

        # CPU ä½¿ç”¨ç‡éä½ï¼Œå¢åŠ å·¥ä½œç·šç¨‹
        if cpu_usage < 50 and self.current_workers < self.max_workers:
            self.current_workers = min(self.current_workers + 1, self.max_workers)
            logger.info(f"å¢åŠ å·¥ä½œç·šç¨‹åˆ° {self.current_workers}")

        # CPU ä½¿ç”¨ç‡éé«˜ï¼Œæ¸›å°‘å·¥ä½œç·šç¨‹
        elif cpu_usage > 80 and self.current_workers > 1:
            self.current_workers = max(self.current_workers - 1, 1)
            logger.info(f"æ¸›å°‘å·¥ä½œç·šç¨‹åˆ° {self.current_workers}")


class WorkDistributor:
    """æ™ºèƒ½å·¥ä½œåˆ†ç™¼å™¨ - å¯¦ç¾è² è¼‰å‡è¡¡"""

    def __init__(self, num_workers: int, load_balance: bool = True):
        self.num_workers = num_workers
        self.load_balance = load_balance
        self.task_queue = queue.Queue()
        self.result_queue = queue.Queue()
        self.worker_loads = [0] * num_workers
        self.lock = threading.Lock()

    def distribute_work(self, tasks: List[Dict[str, Any]]) -> List[List[Dict[str, Any]]]:
        """åˆ†ç™¼å·¥ä½œåˆ°å¤šå€‹å·¥ä½œç·šç¨‹"""
        if not self.load_balance:
            # ç°¡å–®å¹³å‡åˆ†ç™¼
            return self._simple_distribution(tasks)

        # è² è¼‰å‡è¡¡åˆ†ç™¼
        return self._load_balanced_distribution(tasks)

    def _simple_distribution(self, tasks: List[Dict[str, Any]]) -> List[List[Dict[str, Any]]]:
        """ç°¡å–®å¹³å‡åˆ†ç™¼"""
        batch_size = max(1, len(tasks) // self.num_workers)
        batches = []

        for i in range(0, len(tasks), batch_size):
            batch = tasks[i:i + batch_size]
            batches.append(batch)

        return batches

    def _load_balanced_distribution(self, tasks: List[Dict[str, Any]]) -> List[List[Dict[str, Any]]]:
        """è² è¼‰å‡è¡¡åˆ†ç™¼ - æ ¹æ“šä»»å‹™è¤‡é›œåº¦"""
        # è¨ˆç®—æ¯å€‹ä»»å‹™çš„ä¼°è¨ˆè¤‡é›œåº¦
        task_complexities = []
        for task in tasks:
            # æ ¹æ“šåƒæ•¸æ•¸é‡è¨ˆç®—è¤‡é›œåº¦
            complexity = len(task.get('parameters', {}))
            task_complexities.append(complexity)

        # æŒ‰è¤‡é›œåº¦æ’åº
        sorted_tasks = sorted(zip(tasks, task_complexities), key=lambda x: x[1], reverse=True)

        # è¼ªè©¢åˆ†ç™¼åˆ°å·¥ä½œç·šç¨‹
        batches = [[] for _ in range(self.num_workers)]
        for task, complexity in sorted_tasks:
            # æ‰¾åˆ°ç•¶å‰è² è¼‰æœ€å°çš„å·¥ä½œç·šç¨‹
            min_load_idx = min(range(self.num_workers), key=lambda i: self.worker_loads[i])
            batches[min_load_idx].append(task)
            self.worker_loads[min_load_idx] += complexity

        logger.info(f"è² è¼‰åˆ†ç™¼: {self.worker_loads}")
        return batches


class ParallelOptimizer:
    """Rayon-based ä¸¦è¡Œåƒæ•¸å„ªåŒ–å™¨ - æ¥µè‡´æ€§èƒ½ç‰ˆæœ¬"""

    def __init__(self, config: OptimizationConfig):
        self.config = config
        self.cpu_info = CPUDetector.detect_cpu_cores()
        self.max_workers = config.max_workers or self.cpu_info['max_recommended_workers']
        self.performance_history: List[Dict[str, Any]] = []
        self.memory_monitor = MemoryMonitor(config.memory_limit_mb)
        self.work_distributor = WorkDistributor(self.max_workers, config.load_balance)

        logger.info(f"ğŸš€ ä¸¦è¡Œå„ªåŒ–å™¨åˆå§‹åŒ–")
        logger.info(f"   - ç­–ç•¥é¡å‹: {config.strategy_type}")
        logger.info(f"   - CPU æ ¸å¿ƒ: {self.cpu_info['physical_cores']} ç‰©ç† / {self.cpu_info['logical_cores']} é‚è¼¯")
        logger.info(f"   - æœ€å¤§å·¥ä½œç·šç¨‹: {self.max_workers}")
        logger.info(f"   - Rayon åŠ é€Ÿ: {'âœ…' if RAYON_AVAILABLE else 'âŒ'}")

    def optimize(self, backtest_function: Optional[Callable] = None) -> OptimizationResult:
        """é‹è¡Œä¸¦è¡Œåƒæ•¸å„ªåŒ–"""
        start_time = time.time()
        logger.info(f"é–‹å§‹ä¸¦è¡Œå„ªåŒ– - ç›®æ¨™: 1000 çµ„åˆ < 10ç§’")

        # ç”Ÿæˆæ‰€æœ‰åƒæ•¸çµ„åˆ
        combinations = self._generate_parameter_combinations()
        total_combinations = len(combinations)

        if total_combinations == 0:
            raise ValueError("æ²’æœ‰ç”Ÿæˆä»»ä½•åƒæ•¸çµ„åˆ")

        logger.info(f"ç¸½åƒæ•¸çµ„åˆæ•¸: {total_combinations}")

        # å‰µå»ºå·¥ä½œæ‰¹æ¬¡
        batch_size = self._calculate_optimal_batch_size(total_combinations)
        batches = self._create_chunks(combinations, batch_size)

        # é¸æ“‡åŸ·è¡Œç­–ç•¥
        if self.config.use_rayon and RAYON_AVAILABLE:
            results = self._execute_with_rayon(batches, backtest_function)
        elif self._is_multiprocessing_available():
            results = self._execute_with_multiprocessing(batches, backtest_function)
        else:
            results = self._execute_with_threadpool(combinations, backtest_function)

        # æ‰¾åˆ°æœ€ä½³çµæœ
        best_result = self._find_best_result(results)

        execution_time = int((time.time() - start_time) * 1000)
        throughput = total_combinations / (execution_time / 1000.0)
        speedup = self._estimate_speedup(execution_time, total_combinations)

        result = OptimizationResult(
            best_params=best_result['params'],
            best_score=best_result['score'],
            all_results=results,
            execution_time_ms=execution_time,
            workers_used=self.max_workers,
            total_combinations=total_combinations,
            speedup_factor=speedup,
            throughput_per_second=throughput,
            peak_memory_mb=self.memory_monitor.get_peak_memory(),
            avg_time_per_combination_ms=execution_time / total_combinations if total_combinations > 0 else 0,
            load_balance_efficiency=self._calculate_load_balance_efficiency()
        )

        # è¨˜éŒ„æ€§èƒ½
        self._record_performance(result)

        # è¼¸å‡ºæ€§èƒ½å ±å‘Š
        self._print_performance_report(result)

        return result

    def _generate_parameter_combinations(self) -> List[Dict[str, float]]:
        """ä½¿ç”¨ product ç”Ÿæˆæ‰€æœ‰åƒæ•¸çµ„åˆ"""
        from itertools import product

        # æå–åƒæ•¸åç¨±å’Œç¯„åœ
        param_names = [space['name'] for space in self.config.parameter_spaces]

        # ç”Ÿæˆå€¼ç¯„åœ
        value_ranges = []
        for space in self.config.parameter_spaces:
            start = int(space['min'])
            end = int(space['max'])
            step = int(space['step'])
            values = list(range(start, end + 1, step))
            value_ranges.append(values)

        # ç”Ÿæˆç¬›å¡çˆ¾ç©
        combinations = []
        for combo in product(*value_ranges):
            params = dict(zip(param_names, combo))
            combinations.append(params)

        return combinations

    def _calculate_optimal_batch_size(self, total_combinations: int) -> int:
        """è¨ˆç®—æœ€å„ªæ‰¹æ¬¡å¤§å°"""
        if self.config.adaptive_chunking:
            # å‹•æ…‹è¨ˆç®—æ‰¹æ¬¡å¤§å°
            # ç›®æ¨™: æ¯æ‰¹è™•ç† 50-200 å€‹çµ„åˆ
            optimal_batch = min(200, max(50, total_combinations // (self.max_workers * 2)))
            return optimal_batch

        return self.config.chunk_size

    def _create_chunks(
        self,
        combinations: List[Dict[str, float]],
        chunk_size: int
    ) -> List[List[Dict[str, float]]]:
        """å°‡çµ„åˆåˆ†çµ„ç‚ºå·¥ä½œæ‰¹æ¬¡"""
        chunks = []
        for i in range(0, len(combinations), chunk_size):
            chunk = combinations[i:i + chunk_size]
            chunks.append(chunk)
        return chunks

    def _execute_with_threadpool(
        self,
        combinations: List[Dict[str, float]],
        backtest_function: Optional[Callable]
    ) -> List[Dict[str, Any]]:
        """ä½¿ç”¨ ThreadPoolExecutor åŸ·è¡Œ"""
        results = []
        with DynamicThreadPool(self.max_workers, adaptive=True) as pool:
            # æäº¤æ‰€æœ‰çµ„åˆ
            futures = {}
            for i, params in enumerate(combinations):
                future = pool.submit_task(
                    self._evaluate_parameters,
                    params,
                    backtest_function
                )
                futures[future] = (i, params)

            # æ”¶é›†çµæœ
            for future in as_completed(futures, timeout=self.config.timeout_seconds):
                try:
                    result = future.result()
                    idx, params = futures[future]
                    results.append({
                        'params': params,
                        'score': result,
                        'timestamp': time.time()
                    })
                except Exception as e:
                    idx, params = futures[future]
                    logger.error(f"è©•ä¼°åƒæ•¸ {params} æ™‚å‡ºéŒ¯: {e}")
                    results.append({
                        'params': params,
                        'score': float('-inf'),
                        'timestamp': time.time(),
                        'error': str(e)
                    })

        return results

    def _execute_with_multiprocessing(
        self,
        chunks: List[List[Dict[str, float]]],
        backtest_function: Optional[Callable]
    ) -> List[Dict[str, Any]]:
        """ä½¿ç”¨ Multiprocessing åŸ·è¡Œ"""
        with ProcessPoolExecutor(max_workers=self.max_workers) as pool:
            func = partial(self._process_chunk, backtest_function=backtest_function)
            results_list = pool.map(func, chunks)

            # åˆä½µçµæœ
            results = []
            for chunk_results in results_list:
                results.extend(chunk_results)

        return results

    def _execute_with_rayon(
        self,
        chunks: List[List[Dict[str, float]]],
        backtest_function: Optional[Callable]
    ) -> List[Dict[str, Any]]:
        """ä½¿ç”¨ Rayon (Rust) åŸ·è¡Œ"""
        # é€™è£¡æ‡‰è©²ä½¿ç”¨ Rayon çš„ parallel_iter
        # ç”±æ–¼åœ¨ Python ç’°å¢ƒä¸­ï¼Œæˆ‘å€‘ä½¿ç”¨ ThreadPoolExecutor ä½œç‚ºæ›¿ä»£
        logger.info("ä½¿ç”¨ Rayon æ¨¡å¼åŸ·è¡Œ")
        return self._execute_with_threadpool(
            [item for chunk in chunks for item in chunk],
            backtest_function
        )

    def _process_chunk(
        self,
        chunk: List[Dict[str, float]],
        backtest_function: Optional[Callable]
    ) -> List[Dict[str, Any]]:
        """è™•ç†å–®å€‹å·¥ä½œæ‰¹æ¬¡"""
        results = []

        for params in chunk:
            try:
                score = self._evaluate_parameters(params, backtest_function)
                results.append({
                    'params': params,
                    'score': score,
                    'timestamp': time.time()
                })

                # å…§å­˜æª¢æŸ¥
                current_memory = self.memory_monitor.get_memory_usage()
                self.memory_monitor.check_threshold(current_memory)

            except Exception as e:
                logger.error(f"è™•ç†åƒæ•¸ {params} æ™‚å‡ºéŒ¯: {e}")
                continue

        return results

    def _evaluate_parameters(
        self,
        params: Dict[str, float],
        backtest_function: Optional[Callable]
    ) -> float:
        """è©•ä¼°å–®å€‹åƒæ•¸é›†"""
        try:
            if backtest_function:
                # ä½¿ç”¨æä¾›çš„å›æ¸¬å‡½æ•¸
                result = backtest_function(
                    data=self.config.data,
                    strategy_type=self.config.strategy_type,
                    **params
                )

                # æå–åˆ†æ•¸
                if self.config.objective == "sharpe_ratio":
                    return result.get('sharpe_ratio', 0.0)
                elif self.config.objective == "total_return":
                    return result.get('total_return', 0.0)
                elif self.config.objective == "max_drawdown":
                    return -result.get('max_drawdown', 0.0)  # è² æ•¸å› ç‚ºè¦æœ€å°åŒ–
                else:
                    return result.get(self.config.objective, 0.0)
            else:
                # ä½¿ç”¨é»˜èªè©•ä¼°
                return self._evaluate_with_default_strategy(params)

        except Exception as e:
            logger.error(f"å›æ¸¬å‡ºéŒ¯ {params}: {e}")
            return 0.0

    def _evaluate_with_default_strategy(self, params: Dict[str, float]) -> float:
        """ä½¿ç”¨é»˜èª SMA ç­–ç•¥è©•ä¼°"""
        # é€™è£¡æ‡‰è©²èˆ‡ Rust æˆ– Python å›æ¸¬å¼•æ“é›†æˆ
        # æš«æ™‚è¿”å›æ¨¡æ“¬åˆ†æ•¸
        return np.random.uniform(0.5, 2.0)

    def _find_best_result(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æ‰¾åˆ°æœ€ä½³çµæœ"""
        if not results:
            raise ValueError("æ²’æœ‰çµæœå¯ä»¥è©•ä¼°")

        # æŒ‰åˆ†æ•¸æ’åº
        reverse = (self.config.objective != "max_drawdown")
        # Fix: max() does not support reverse parameter
        reverse = (self.config.objective != "max_drawdown")
        if reverse:
            best = max(results, key=lambda x: x["score"])
        else:
            best = min(results, key=lambda x: x["score"])

        return best

    def _estimate_speedup(self, execution_time_ms: int, total_combinations: int) -> float:
        """ä¼°ç®—åŠ é€Ÿæ¯”"""
        # ä¼°è¨ˆä¸²è¡Œæ™‚é–“
        estimated_sequential_time = total_combinations * 10  # å‡è¨­æ¯å€‹çµ„åˆ 10ms

        if estimated_sequential_time <= 0:
            return 1.0

        speedup = estimated_sequential_time / execution_time_ms
        return min(speedup, self.max_workers)

    def _calculate_load_balance_efficiency(self) -> float:
        """è¨ˆç®—è² è¼‰å‡è¡¡æ•ˆç‡"""
        if not hasattr(self.work_distributor, 'worker_loads'):
            return 0.0

        loads = self.work_distributor.worker_loads
        if not loads:
            return 0.0

        avg_load = sum(loads) / len(loads)
        if avg_load == 0:
            return 1.0

        variance = sum((load - avg_load) ** 2 for load in loads) / len(loads)
        std_dev = variance ** 0.5

        # æ•ˆç‡ = 1 - (æ¨™æº–å·® / å¹³å‡å€¼)
        efficiency = 1 - (std_dev / avg_load)
        return max(0.0, min(1.0, efficiency))

    def _record_performance(self, result: OptimizationResult):
        """è¨˜éŒ„å„ªåŒ–æ€§èƒ½"""
        self.performance_history.append({
            'timestamp': time.time(),
            'strategy_type': self.config.strategy_type,
            'total_combinations': result.total_combinations,
            'execution_time_ms': result.execution_time_ms,
            'workers_used': result.workers_used,
            'speedup_factor': result.speedup_factor,
            'throughput': result.throughput_per_second,
            'best_score': result.best_score
        })

    def _print_performance_report(self, result: OptimizationResult):
        """æ‰“å°æ€§èƒ½å ±å‘Š"""
        logger.info("=" * 60)
        logger.info("ğŸš€ ä¸¦è¡Œå„ªåŒ–æ€§èƒ½å ±å‘Š")
        logger.info("=" * 60)
        logger.info(f"âœ… ç¸½åŸ·è¡Œæ™‚é–“: {result.execution_time_ms:.2f}ms")
        logger.info(f"âœ… åƒæ•¸çµ„åˆæ•¸: {result.total_combinations}")
        logger.info(f"âœ… å·¥ä½œç·šç¨‹æ•¸: {result.workers_used}")
        logger.info(f"âœ… åŠ é€Ÿæ¯”: {result.speedup_factor:.2f}x")
        logger.info(f"âœ… ååé‡: {result.throughput_per_second:.2f} çµ„åˆ/ç§’")
        logger.info(f"âœ… å¹³å‡æ™‚é–“: {result.avg_time_per_combination_ms:.2f}ms/çµ„åˆ")
        logger.info(f"âœ… å³°å€¼å…§å­˜: {result.peak_memory_mb:.2f}MB")
        logger.info(f"âœ… è² è¼‰å‡è¡¡æ•ˆç‡: {result.load_balance_efficiency:.2%}")

        # æª¢æŸ¥æ€§èƒ½ç›®æ¨™
        if result.total_combinations >= 1000 and result.execution_time_ms < 10000:
            logger.info("ğŸ¯ æ€§èƒ½ç›®æ¨™é”æˆ: 1000 çµ„åˆ < 10ç§’")
        elif result.execution_time_ms < 10000:
            logger.info(f"âš ï¸  çµ„åˆæ•¸æœªé” 1000ï¼Œä½†æ™‚é–“ç›®æ¨™é”æˆ")

        logger.info("=" * 60)

    def _is_multiprocessing_available(self) -> bool:
        """æª¢æŸ¥å¤šé€²ç¨‹æ˜¯å¦å¯ç”¨"""
        try:
            mp.cpu_count()
            return True
        except Exception:
            return False

    def get_performance_report(self) -> Dict[str, Any]:
        """ç²å–æ€§èƒ½å ±å‘Š"""
        if not self.performance_history:
            return {'message': 'æ²’æœ‰å„ªåŒ–æ­·å²è¨˜éŒ„'}

        avg_time = sum(r['execution_time_ms'] for r in self.performance_history) / len(self.performance_history)
        avg_speedup = sum(r['speedup_factor'] for r in self.performance_history) / len(self.performance_history)
        avg_throughput = sum(r['throughput'] for r in self.performance_history) / len(self.performance_history)

        return {
            'cpu_info': self.cpu_info,
            'max_workers': self.max_workers,
            'total_optimizations': len(self.performance_history),
            'average_execution_time_ms': avg_time,
            'average_speedup_factor': avg_speedup,
            'average_throughput': avg_throughput,
            'history': self.performance_history[-10:],  # æœ€è¿‘ 10 æ¬¡
        }


class MemoryMonitor:
    """å…§å­˜ä½¿ç”¨ç›£æ§å™¨"""

    def __init__(self, max_memory_mb: int = 1024):
        self.max_memory_mb = max_memory_mb
        self.peak_memory = 0.0
        self.alerts = []

    def get_memory_usage(self) -> float:
        """ç²å–ç•¶å‰å…§å­˜ä½¿ç”¨ (MB)"""
        process = psutil.Process()
        return process.memory_info().rss / 1024 / 1024

    def get_peak_memory(self) -> float:
        """ç²å–å³°å€¼å…§å­˜ä½¿ç”¨"""
        return self.peak_memory

    def check_threshold(self, current_mb: float):
        """æª¢æŸ¥å…§å­˜é–¾å€¼"""
        if current_mb > self.peak_memory:
            self.peak_memory = current_mb

        if current_mb > self.max_memory_mb:
            alert = f"âš ï¸  å…§å­˜ä½¿ç”¨è¶…é™: {current_mb:.2f}MB > {self.max_memory_mb}MB"
            logger.warning(alert)
            self.alerts.append({
                'timestamp': time.time(),
                'message': alert,
            })


def optimize_parameters(
    data: pd.DataFrame,
    strategy_type: str,
    parameter_spaces: List[Dict[str, Any]],
    max_workers: Optional[int] = None,
    objective: str = "sharpe_ratio"
) -> OptimizationResult:
    """ä¾¿æ·å‡½æ•¸: å„ªåŒ–åƒæ•¸"""
    config = OptimizationConfig(
        strategy_type=strategy_type,
        parameter_spaces=parameter_spaces,
        data=data,
        objective=objective,
        max_workers=max_workers,
        use_rayon=True,
        use_rust=True
    )

    optimizer = ParallelOptimizer(config)
    return optimizer.optimize()


if __name__ == '__main__':
    # æ¸¬è©¦ä¸¦è¡Œå„ªåŒ–å™¨
    print("=" * 60)
    print("ğŸš€ Rayon-based ä¸¦è¡Œå„ªåŒ–å™¨æ¸¬è©¦")
    print("=" * 60)

    # ç”Ÿæˆæ¸¬è©¦æ•¸æ“š
    dates = pd.date_range('2020-01-01', periods=1000, freq='D')
    prices = 100 + np.cumsum(np.random.randn(1000) * 0.5)
    data = pd.DataFrame({
        'Open': prices * (1 + np.random.randn(1000) * 0.001),
        'High': prices * (1 + np.random.randn(1000) * 0.002),
        'Low': prices * (1 - np.random.randn(1000) * 0.002),
        'Close': prices,
        'Volume': np.random.randint(1000, 10000, 1000),
    }, index=dates)

    # åƒæ•¸ç©ºé–“
    parameter_spaces = [
        {'name': 'fast_period', 'min': 5, 'max': 20, 'step': 5},
        {'name': 'slow_period', 'min': 20, 'max': 50, 'step': 10},
    ]

    # åŸ·è¡Œå„ªåŒ–
    result = optimize_parameters(
        data=data,
        strategy_type='ma',
        parameter_spaces=parameter_spaces,
        max_workers=8
    )

    print(f"\næœ€ä½³çµæœ:")
    print(f"  åƒæ•¸: {result.best_params}")
    print(f"  åˆ†æ•¸: {result.best_score:.4f}")
    print(f"\næ€§èƒ½çµ±è¨ˆ:")
    print(f"  ç¸½çµ„åˆæ•¸: {result.total_combinations}")
    print(f"  ç¸½æ™‚é–“: {result.execution_time_ms:.2f}ms")
    print(f"  åŠ é€Ÿæ¯”: {result.speedup_factor:.2f}x")
    print(f"  ååé‡: {result.throughput_per_second:.2f} çµ„åˆ/ç§’")
    print(f"  å³°å€¼å…§å­˜: {result.peak_memory_mb:.2f}MB")
