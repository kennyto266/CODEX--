#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¸¯è‚¡æƒ…ç»ªåˆ†æä»£ç† (HK Stock Sentiment Analyst)
ä¸“æ³¨é«˜Sharpe Ratioäº¤æ˜“ç­–ç•¥çš„é‡åŒ–æƒ…ç»ªåˆ†æ
"""

import json
import re
import math
from datetime import datetime
from typing import Dict, List, Tuple, Any

class HKSentimentAnalyzer:
    """æ¸¯è‚¡æƒ…ç»ªåˆ†æä»£ç†"""
    
    def __init__(self):
        # æ¸¯è‚¡æƒ…ç»ªå…³é”®è¯è¯å…¸
        self.positive_keywords = {
            'æ¶¨': 0.8, 'å‡': 0.7, 'å¼ºåŠ²': 0.9, 'çœ‹å¥½': 0.8, 'çªç ´': 0.8,
            'ä¹°å…¥': 0.9, 'ç‰›å¸‚': 1.0, 'ä¸Šæ¶¨': 0.8, 'åˆ©å¥½': 0.9, 'å¢é•¿': 0.7,
            'æ”¶ç›Š': 0.6, 'ç›ˆåˆ©': 0.8, 'æˆé•¿': 0.7, 'æœºä¼š': 0.6, 'æ¨è': 0.8,
            'è…¾è®¯å¼ºåŠ²': 0.9, 'æ¸¯è‚¡é€š': 0.6, 'åŒ—æ°´': 0.7, 'èµ„é‡‘æµå…¥': 0.8
        }
        
        self.negative_keywords = {
            'è·Œ': -0.8, 'ä¸‹è·Œ': -0.8, 'æš´è·Œ': -1.0, 'ææ…Œ': -0.9, 'æŠ›å”®': -0.8,
            'å–å‡º': -0.9, 'ç†Šå¸‚': -1.0, 'äºæŸ': -0.8, 'é£é™©': -0.6, 'è­¦å‘Š': -0.7,
            'è´¸æ˜“æˆ˜': -0.9, 'åˆ¶è£': -1.0, 'åœ°ç¼˜': -0.7, 'è¡°é€€': -0.9, 'å´©ç›˜': -1.0,
            'èµ„é‡‘å¤–æµ': -0.8, 'å—æ°´': -0.5, 'ç›‘ç®¡': -0.6, 'è°ƒæ•´': -0.4
        }
        
        # æ¸¯è‚¡ç‰¹å®šè‚¡ç¥¨ä»£ç æƒé‡
        self.hk_stock_weights = {
            '0700': 1.2,  # è…¾è®¯
            '0939': 1.1,  # å»ºè®¾é“¶è¡Œ  
            '0941': 1.1,  # ä¸­å›½ç§»åŠ¨
            '0388': 1.0,  # æ¸¯äº¤æ‰€
            '2318': 1.1,  # å¹³å®‰ä¿é™©
            '1299': 1.0,  # å‹é‚¦ä¿é™©
            '0005': 1.0,  # æ±‡ä¸°æ§è‚¡
        }
    
    def extract_sentiment_score(self, text: str) -> float:
        """æå–å•æ¡æ–‡æœ¬çš„æƒ…ç»ªåˆ†æ•° (-1 to 1)"""
        if not text:
            return 0.0
            
        # ç®€åŒ–çš„ä¸­æ–‡åˆ†è¯ (ä½¿ç”¨å­—ç¬¦çº§åˆ«åŒ¹é…)
        sentiment_score = 0.0
        word_count = 0
        
        # æ£€æŸ¥æ­£é¢å…³é”®è¯
        for keyword, score in self.positive_keywords.items():
            if keyword in text:
                sentiment_score += score
                word_count += 1
                
        # æ£€æŸ¥è´Ÿé¢å…³é”®è¯  
        for keyword, score in self.negative_keywords.items():
            if keyword in text:
                sentiment_score += score
                word_count += 1
        
        # æ ‡å‡†åŒ–åˆ†æ•°
        if word_count > 0:
            sentiment_score = sentiment_score / word_count
            
        # é™åˆ¶åœ¨ [-1, 1] èŒƒå›´å†…
        return max(-1.0, min(1.0, sentiment_score))
    
    def calculate_volume_weighted_sentiment(self, posts: List[str], volumes: List[float]) -> List[float]:
        """è®¡ç®—æˆäº¤é‡åŠ æƒæƒ…ç»ªåˆ†æ•°"""
        sentiment_scores = []
        
        for i, post in enumerate(posts):
            base_sentiment = self.extract_sentiment_score(post)
            
            # æˆäº¤é‡æƒé‡ (æ ‡å‡†åŒ–åˆ°0.5-1.5å€æ•°)
            if i < len(volumes) and volumes:
                volume_weight = 0.5 + (volumes[i] / max(volumes)) if max(volumes) > 0 else 1.0
                weighted_sentiment = base_sentiment * volume_weight
            else:
                weighted_sentiment = base_sentiment
                
            sentiment_scores.append(max(-1.0, min(1.0, weighted_sentiment)))
            
        return sentiment_scores
    
    def detect_sentiment_bias(self, sentiment_scores: List[float]) -> Dict[str, Any]:
        """è¯†åˆ«æƒ…ç»ªåå·®å’Œå¼‚å¸¸å€¼"""
        if not sentiment_scores:
            return {"bias_type": "neutral", "extreme_count": 0, "volatility": 0.0}
            
        # ä½¿ç”¨çº¯Pythonè®¡ç®—ç»Ÿè®¡å€¼
        mean_sentiment = sum(sentiment_scores) / len(sentiment_scores)
        variance = sum((x - mean_sentiment) ** 2 for x in sentiment_scores) / len(sentiment_scores)
        std_sentiment = math.sqrt(variance)
        
        # è¯†åˆ«æç«¯æƒ…ç»ª (< -0.5 æˆ– > 0.8)
        extreme_negative = sum(1 for score in sentiment_scores if score < -0.5)
        extreme_positive = sum(1 for score in sentiment_scores if score > 0.8)
        
        bias_type = "neutral"
        if mean_sentiment > 0.3:
            bias_type = "bullish"
        elif mean_sentiment < -0.3:
            bias_type = "bearish"
            
        return {
            "bias_type": bias_type,
            "extreme_negative": int(extreme_negative),
            "extreme_positive": int(extreme_positive), 
            "volatility": float(std_sentiment),
            "mean_sentiment": float(mean_sentiment)
        }
    
    def calculate_sharpe_contribution(self, sentiment_scores: List[float], volatility: float) -> float:
        """è®¡ç®—æƒ…ç»ªå¯¹Sharpe Ratioçš„è´¡çŒ® (-1 to 1)"""
        if not sentiment_scores:
            return 0.0
            
        mean_sentiment = sum(sentiment_scores) / len(sentiment_scores)
        
        # æƒ…ç»ªç¨³å®šæ€§è´¡çŒ® (ä½æ³¢åŠ¨ç‡ = æ­£è´¡çŒ®)
        stability_contribution = max(0, (0.5 - volatility) / 0.5) * 0.4
        
        # æƒ…ç»ªæ–¹å‘è´¡çŒ® (æ­£é¢æƒ…ç»ª = æ­£è´¡çŒ®)
        direction_contribution = mean_sentiment * 0.6
        
        total_contribution = stability_contribution + direction_contribution
        
        return max(-1.0, min(1.0, total_contribution))
    
    def generate_trading_recommendations(self, analysis_result: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆäº¤æ˜“å»ºè®®"""
        recommendations = []
        
        avg_score = analysis_result['avg_score']
        bias = analysis_result['sentiment_bias']
        sharpe_contrib = analysis_result['sharpe_contribution']
        
        # ä¹°å…¥å»ºè®®
        if avg_score > 0.5 and bias['extreme_negative'] == 0:
            recommendations.append("ğŸŸ¢ ä¹°å…¥ä¿¡å·ï¼šæƒ…ç»ªæŒç»­æ­£é¢ï¼Œå»ºè®®é€æ­¥å»ºä»“ä¼˜è´¨æ¸¯è‚¡")
            
        if sharpe_contrib > 0.3:
            recommendations.append("ğŸ“ˆ é£é™©è°ƒæ•´æ”¶ç›Šè‰¯å¥½ï¼šæƒ…ç»ªç¨³å®šæ”¯æ’‘é«˜Sharpeç­–ç•¥")
            
        # å–å‡º/è§„é¿å»ºè®®
        if avg_score < -0.5 or bias['extreme_negative'] > 2:
            recommendations.append("ğŸ”´ è§„é¿ä¿¡å·ï¼šè´Ÿé¢æƒ…ç»ªæµ“åšï¼Œå»ºè®®å‡ä»“æˆ–è§‚æœ›")
            
        if bias['volatility'] > 0.6:
            recommendations.append("âš ï¸ æƒ…ç»ªæ³¢åŠ¨é£é™©ï¼šå»ºè®®é™ä½ä»“ä½æ§åˆ¶å›æ’¤")
            
        # ä¸­æ€§å»ºè®®
        if -0.2 <= avg_score <= 0.2:
            recommendations.append("ğŸŸ¡ ä¸­æ€§è§‚æœ›ï¼šæƒ…ç»ªåˆ†æ­§æ˜æ˜¾ï¼Œç­‰å¾…æ˜ç¡®ä¿¡å·")
            
        # ç‰¹æ®Šæƒ…å†µ
        if bias['extreme_positive'] > 3:
            recommendations.append("âš¡ æƒ…ç»ªè¿‡çƒ­è­¦å‘Šï¼šæ³¨æ„è¿½æ¶¨é£é™©ï¼Œè€ƒè™‘åˆ†æ‰¹è·åˆ©äº†ç»“")
            
        return recommendations[:5]  # é™åˆ¶åœ¨5æ¡ä»¥å†…
    
    def analyze_hk_stock_sentiment(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ä¸»åˆ†æå‡½æ•°"""
        
        # æå–è¾“å…¥æ•°æ®
        stock_code = data.get('stock', '')
        posts = data.get('posts', [])
        volumes = data.get('volumes', [])
        dates = data.get('dates', [f"2024-09-{28-i}" for i in range(len(posts))])
        
        # 1. è®¡ç®—æƒ…ç»ªåˆ†æ•°
        sentiment_scores = self.calculate_volume_weighted_sentiment(posts, volumes)
        
        # 2. è¯†åˆ«æƒ…ç»ªåå·®
        sentiment_bias = self.detect_sentiment_bias(sentiment_scores)
        
        # 3. è®¡ç®—å¹³å‡æƒ…ç»ª
        avg_score = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0.0
        
        # 4. è¯„ä¼°Sharpeè´¡çŒ®
        sharpe_contribution = self.calculate_sharpe_contribution(
            sentiment_scores, sentiment_bias['volatility']
        )
        
        # 5. ç”Ÿæˆåˆ†æç»“æœ
        analysis_result = {
            'avg_score': avg_score,
            'sentiment_bias': sentiment_bias,
            'sharpe_contribution': sharpe_contribution
        }
        
        # 6. ç”Ÿæˆäº¤æ˜“å»ºè®®
        recommendations = self.generate_trading_recommendations(analysis_result)
        
        # æ„å»ºæœ€ç»ˆè¾“å‡º
        result = {
            "stock_code": stock_code,
            "analysis_date": datetime.now().strftime("%Y-%m-%d"),
            "sentiment_scores": [
                {"date": dates[i] if i < len(dates) else f"day_{i}", 
                 "score": round(score, 3)} 
                for i, score in enumerate(sentiment_scores)
            ],
            "avg_score": round(avg_score, 3),
            "sentiment_bias": {
                "type": sentiment_bias['bias_type'],
                "volatility": round(sentiment_bias['volatility'], 3),
                "extreme_negative_count": sentiment_bias['extreme_negative'],
                "extreme_positive_count": sentiment_bias['extreme_positive']
            },
            "sharpe_contribution": round(sharpe_contribution, 3),
            "recommendations": recommendations,
            "risk_assessment": {
                "overall_risk": "HIGH" if sentiment_bias['volatility'] > 0.6 else "MEDIUM" if sentiment_bias['volatility'] > 0.3 else "LOW",
                "sentiment_contagion_risk": "HIGH" if abs(avg_score) > 0.7 else "MEDIUM",
                "drawdown_risk": "HIGH" if sentiment_bias['extreme_negative'] > 2 else "LOW"
            }
        }
        
        return result

def main():
    """ç¤ºä¾‹è¿è¡Œ"""
    analyzer = HKSentimentAnalyzer()
    
    # ç¤ºä¾‹æ•°æ®
    sample_data = {
        "stock": "0700.HK",
        "posts": [
            "è…¾è®¯å¼ºåŠ²æˆé•¿ï¼Q3ä¸šç»©è¶…é¢„æœŸï¼Œæ¸¸æˆæ”¶å…¥å¤§æ¶¨",
            "æ¸¯è‚¡é€šèµ„é‡‘å¤§å¹…æµå…¥è…¾è®¯ï¼ŒåŒ—æ°´çœ‹å¥½ç§‘æŠ€è‚¡",
            "å¸‚åœºææ…Œæƒ…ç»ªè”“å»¶ï¼Œç§‘æŠ€è‚¡å…¨çº¿ä¸‹è·Œ", 
            "è…¾è®¯äº‘ä¸šåŠ¡å¢é•¿å¼ºåŠ²ï¼ŒAIæ¦‚å¿µæŒç»­å‘é…µ",
            "ç¾è‚¡ç§‘æŠ€è‚¡æš´è·Œï¼Œæ¸¯è‚¡ç§‘æŠ€è‚¡æ‰¿å‹"
        ],
        "volumes": [15000000, 12000000, 8000000, 18000000, 6000000],
        "dates": ["2024-09-24", "2024-09-25", "2024-09-26", "2024-09-27", "2024-09-28"]
    }
    
    result = analyzer.analyze_hk_stock_sentiment(sample_data)
    print(json.dumps(result, ensure_ascii=False, indent=2))

if __name__ == "__main__":
    main()