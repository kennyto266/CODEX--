import { PlaywrightCrawler } from 'crawlee';
import fs from 'fs';
import path from 'path';
import { router } from './routes_csv.js';

// Configuration
const DATA_DIR = 'data';

async function main() {
  // Create data directory if not exists
  if (!fs.existsSync(DATA_DIR)) {
    fs.mkdirSync(DATA_DIR, { recursive: true });
  }

  // å–®ä¸€è«‹æ±‚ï¼Œæœƒè‡ªå‹•åµæ¸¬æ‰€æœ‰å¯é»æ“Šçš„æ—¥æœŸ
  const startUrls = [{
    url: 'https://www.hkex.com.hk/chi/stat/smstat/dayquot/qtn_c.asp',
    userData: {
      extractAllDates: true  // å‘Šè¨´ router è¦æå–æ‰€æœ‰æ—¥æœŸ
    }
  }];

  console.log(`ğŸš€ Starting crawler to extract ALL clickable dates...`);

  const crawler = new PlaywrightCrawler({
    requestHandler: router,
    maxRequestsPerCrawl: 1,
    maxRequestRetries: 0,
    navigationTimeoutSecs: 180,  // 3åˆ†é˜è¶…æ™‚
  });

  try {
    await crawler.run(startUrls);
    console.log('âœ… Crawler completed!');

    // é¡¯ç¤ºç”Ÿæˆçš„CSVæ–‡ä»¶
    const csvFiles = fs.readdirSync(DATA_DIR).filter(f => f.startsWith('hkex_market_data_') && f.endsWith('.csv'));
    console.log(`ğŸ“Š Generated ${csvFiles.length} CSV files`);
  } catch (error) {
    console.error('âŒ Crawler error:', error);
  }
}

main().catch(console.error);
