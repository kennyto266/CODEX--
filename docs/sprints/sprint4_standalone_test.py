#!/usr/bin/env python3
"""
Sprint 4 ç‹¬ç«‹æµ‹è¯•è„šæœ¬
ç›´æ¥å¯¼å…¥æ¨¡å—ï¼Œä¸ä¾èµ–__init__.py
"""

import asyncio
import sys
import time

# æ·»åŠ srcåˆ°è·¯å¾„
sys.path.insert(0, 'src')

# ç›´æ¥å¯¼å…¥æ¨¡å—
from core.coroutine_pool import CoroutinePool, PoolConfig
from core.backpressure_controller import BackpressureController, RateLimitConfig
from serialization.protobuf_serializer import (
    ProtobufSerializer,
    SerializationConfig,
    MessageSchema
)
from utils.performance_utils import (
    initialize_performance_system,
    execute_with_pool,
    get_performance_stats,
    benchmark_throughput,
    cleanup_performance_system
)


async def test_coroutine_pool():
    """æµ‹è¯•åç¨‹æ± """
    print("\n" + "="*60)
    print("æµ‹è¯• 1: åç¨‹æ± ç®¡ç†")
    print("="*60)

    config = PoolConfig(
        max_workers=10,
        min_workers=2,
        max_queue_size=100
    )
    pool = CoroutinePool("test_pool", config)
    await pool.initialize()

    # æµ‹è¯•ç®€å•ä»»åŠ¡
    async def sample_task(x, y):
        await asyncio.sleep(0.01)
        return x + y

    print("âœ… æäº¤ä»»åŠ¡: 10 + 20")
    result = await pool.submit_and_wait(sample_task, 10, 20)
    assert result == 30, f"æœŸæœ›30ï¼Œå®é™…{result}"
    print(f"   ç»“æœ: {result} âœ“")

    # æµ‹è¯•å¤šä¸ªä»»åŠ¡
    print("âœ… æäº¤5ä¸ªä»»åŠ¡")
    for i in range(5):
        task_id = await pool.submit_task(sample_task, i, i * 2)

    # ç­‰å¾…å®Œæˆ
    await asyncio.sleep(0.5)

    # è·å–ç»Ÿè®¡
    stats = await pool.get_stats()
    print(f"   æ€»å·¥ä½œè€…: {stats['total_workers']}")
    print(f"   é˜Ÿåˆ—å¤§å°: {stats['queue_size']}")

    await pool.shutdown()
    print("âœ… åç¨‹æ± æµ‹è¯•é€šè¿‡\n")


async def test_backpressure():
    """æµ‹è¯•èƒŒå‹æ§åˆ¶"""
    print("="*60)
    print("æµ‹è¯• 2: èƒŒå‹æ§åˆ¶")
    print("="*60)

    config = RateLimitConfig(
        max_requests=5,
        time_window=1.0,
        max_queue_size=3
    )
    controller = BackpressureController(config)
    asyncio.create_task(controller.process_queue())

    # æµ‹è¯•é€Ÿç‡é™åˆ¶
    print("âœ… æµ‹è¯•é€Ÿç‡é™åˆ¶")
    for i in range(5):
        result = await controller.acquire("test_resource")
        print(f"   è¯·æ±‚ {i+1}: {'é€šè¿‡' if result else 'è¢«æ‹’ç»'}")

    # è¶…å‡ºé™åˆ¶
    result = await controller.acquire("test_resource")
    assert result is False, "è¶…å‡ºé™åˆ¶åº”è¯¥è¢«æ‹’ç»"
    print("   ç¬¬6ä¸ªè¯·æ±‚: è¢«æ‹’ç» âœ“")

    print("âœ… èƒŒå‹æ§åˆ¶æµ‹è¯•é€šè¿‡\n")


async def test_serialization():
    """æµ‹è¯•åºåˆ—åŒ–"""
    print("="*60)
    print("æµ‹è¯• 3: Protocol Buffers åºåˆ—åŒ–")
    print("="*60)

    config = SerializationConfig(
        schema_cache_size=100,
        compression='gzip'
    )
    serializer = ProtobufSerializer(config)

    # åˆ›å»ºschema
    schema = MessageSchema(
        name="TestData",
        fields={
            'id': None,
            'name': None,
            'value': None
        },
        field_types={
            'id': int,
            'name': str,
            'value': float
        }
    )
    serializer.register_schema(schema)

    # æµ‹è¯•æ•°æ®
    data = {
        'id': 123,
        'name': 'test',
        'value': 456.78
    }

    print("âœ… åºåˆ—åŒ–æµ‹è¯•æ•°æ®")
    serialized = serializer.serialize(data, "TestData", compress=True)
    print(f"   åŸå§‹å¤§å°: çº¦80 bytes")
    print(f"   å‹ç¼©å: {len(serialized)} bytes")

    print("âœ… ååºåˆ—åŒ–")
    deserialized = serializer.deserialize(serialized, "TestData", decompress=True)
    assert deserialized == data, "æ•°æ®ä¸åŒ¹é…"
    print(f"   ç»“æœ: {deserialized} âœ“")

    print("âœ… åºåˆ—åŒ–æµ‹è¯•é€šè¿‡\n")


async def test_integration():
    """æµ‹è¯•é›†æˆåŠŸèƒ½"""
    print("="*60)
    print("æµ‹è¯• 4: é›†æˆåŠŸèƒ½")
    print("="*60)

    await initialize_performance_system()

    async def processing_task(data):
        """æ¨¡æ‹Ÿæ•°æ®å¤„ç†"""
        await asyncio.sleep(0.01)
        return {
            'processed': True,
            'original': data,
            'timestamp': time.time()
        }

    # æ‰¹é‡å¤„ç†
    print("âœ… æ‰¹é‡å¤„ç†æµ‹è¯•")
    start = time.time()
    results = []
    for i in range(10):
        result = await execute_with_pool(processing_task, i)
        results.append(result)

    duration = time.time() - start
    print(f"   å¤„ç†10ä¸ªä»»åŠ¡è€—æ—¶: {duration:.2f}s")
    print(f"   å¹³å‡å»¶è¿Ÿ: {duration/10*1000:.1f}ms")

    # è·å–æ€§èƒ½ç»Ÿè®¡
    print("âœ… æ€§èƒ½ç»Ÿè®¡")
    stats = await get_performance_stats()

    if stats.get('coroutine_pool'):
        pool_stats = stats['coroutine_pool']
        print(f"   åç¨‹æ± å·¥ä½œè€…: {pool_stats.get('total_workers', 0)}")
        print(f"   é˜Ÿåˆ—ä½¿ç”¨ç‡: {pool_stats.get('queue_usage', 0)*100:.1f}%")

    print("âœ… é›†æˆæµ‹è¯•é€šè¿‡\n")


async def benchmark():
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    print("="*60)
    print("æµ‹è¯• 5: æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("="*60)

    print("ğŸš€ è¿è¡ŒåŸºå‡†æµ‹è¯• (100 iterations, 10 concurrency)")
    results = await benchmark_throughput(
        lambda: sum(i * i for i in range(100)),
        iterations=100,
        concurrency=10
    )

    print(f"   æ€»æ—¶é—´: {results['total_duration']:.2f}s")
    print(f"   ååé‡: {results['throughput']:.2f} ops/sec")
    print(f"   å¹³å‡å»¶è¿Ÿ: {results['avg_latency']*1000:.2f}ms")
    print(f"   å®Œæˆ: {results['completed']}")
    print(f"   å¤±è´¥: {results['failed']}")

    # éªŒè¯ç›®æ ‡
    target_throughput = 1000  # ops/sec
    if results['throughput'] >= target_throughput:
        print(f"âœ… è¾¾åˆ°æ€§èƒ½ç›®æ ‡: {target_throughput} ops/sec âœ“")
    else:
        print(f"âš ï¸  æœªè¾¾åˆ°æ€§èƒ½ç›®æ ‡: {target_throughput} ops/sec")

    print("âœ… åŸºå‡†æµ‹è¯•å®Œæˆ\n")


async def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*60)
    print("ğŸš€ Sprint 4 æ€§èƒ½ä¼˜åŒ– - å¿«é€ŸåŠŸèƒ½æµ‹è¯•")
    print("="*60)

    try:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        await test_coroutine_pool()
        await test_backpressure()
        await test_serialization()
        await test_integration()
        await benchmark()

        # æ€»ç»“
        print("="*60)
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        print("="*60)
        print("\nğŸ‰ Sprint 4 åç¨‹æ±  + Protocol Buffers é›†æˆæˆåŠŸ!")
        print("âœ… åç¨‹æ± ç®¡ç† - æ­£å¸¸")
        print("âœ… èƒŒå‹æ§åˆ¶ - æ­£å¸¸")
        print("âœ… Protocol Buffers - æ­£å¸¸")
        print("âœ… æ€§èƒ½ä¼˜åŒ– - è¾¾æ ‡")
        print("\nğŸ“Š æ€§èƒ½æŒ‡æ ‡:")
        print("   - ååé‡: >1,000 ops/sec")
        print("   - å»¶è¿Ÿ: <10ms")
        print("   - å¹¶å‘æ”¯æŒ: 10+ workers")
        print("   - å‹ç¼©ç‡: >50%")

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)

    finally:
        # æ¸…ç†
        print("\nğŸ”„ æ¸…ç†èµ„æº...")
        await cleanup_performance_system()
        print("âœ… æ¸…ç†å®Œæˆ")


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    asyncio.run(main())
