"""
ä»£ç è´¨é‡æ£€æŸ¥æŠ¥å‘Š - QAå®¡æŸ¥
"""

import ast
import re
from typing import Dict, List, Any, Tuple
from collections import defaultdict
import os

class CodeQualityAnalyzer:
    """ä»£ç è´¨é‡åˆ†æå™¨"""
    
    def __init__(self):
        self.issues = defaultdict(list)
        self.metrics = {}
    
    def analyze_file(self, filepath: str) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # è§£æAST
            tree = ast.parse(content)
            
            # åˆ†æä»£ç è´¨é‡
            self._analyze_imports(tree)
            self._analyze_functions(tree)
            self._analyze_classes(tree)
            self._analyze_complexity(tree)
            self._analyze_naming_conventions(tree)
            self._analyze_docstrings(tree)
            
            # è®¡ç®—æŒ‡æ ‡
            self._calculate_metrics(content, tree)
            
            return {
                'filepath': filepath,
                'issues': dict(self.issues),
                'metrics': self.metrics
            }
            
        except Exception as e:
            return {
                'filepath': filepath,
                'error': str(e),
                'issues': {},
                'metrics': {}
            }
    
    def _analyze_imports(self, tree: ast.AST):
        """åˆ†æå¯¼å…¥è¯­å¥"""
        imports = []
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    imports.append(alias.name)
            elif isinstance(node, ast.ImportFrom):
                module = node.module or ''
                for alias in node.names:
                    imports.append(f"{module}.{alias.name}")
        
        # æ£€æŸ¥æœªä½¿ç”¨çš„å¯¼å…¥
        used_names = set()
        for node in ast.walk(tree):
            if isinstance(node, ast.Name):
                used_names.add(node.id)
        
        for imp in imports:
            if imp.split('.')[-1] not in used_names:
                self.issues['unused_imports'].append(imp)
    
    def _analyze_functions(self, tree: ast.AST):
        """åˆ†æå‡½æ•°"""
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                # æ£€æŸ¥å‡½æ•°é•¿åº¦
                if node.end_lineno - node.lineno > 50:
                    self.issues['long_functions'].append({
                        'name': node.name,
                        'lines': node.end_lineno - node.lineno
                    })
                
                # æ£€æŸ¥å‚æ•°æ•°é‡
                if len(node.args.args) > 5:
                    self.issues['too_many_parameters'].append({
                        'name': node.name,
                        'count': len(node.args.args)
                    })
                
                # æ£€æŸ¥è¿”å›å€¼ç±»å‹æ³¨è§£
                if not node.returns:
                    self.issues['missing_return_type'].append(node.name)
    
    def _analyze_classes(self, tree: ast.AST):
        """åˆ†æç±»"""
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                # æ£€æŸ¥ç±»æ–¹æ³•æ•°é‡
                methods = [n for n in node.body if isinstance(n, ast.FunctionDef)]
                if len(methods) > 10:
                    self.issues['large_classes'].append({
                        'name': node.name,
                        'methods': len(methods)
                    })
                
                # æ£€æŸ¥æ˜¯å¦æœ‰__init__æ–¹æ³•
                has_init = any(m.name == '__init__' for m in methods)
                if not has_init and len(methods) > 0:
                    self.issues['missing_init'].append(node.name)
    
    def _analyze_complexity(self, tree: ast.AST):
        """åˆ†æä»£ç å¤æ‚åº¦"""
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                complexity = self._calculate_cyclomatic_complexity(node)
                if complexity > 10:
                    self.issues['high_complexity'].append({
                        'name': node.name,
                        'complexity': complexity
                    })
    
    def _calculate_cyclomatic_complexity(self, node: ast.FunctionDef) -> int:
        """è®¡ç®—åœˆå¤æ‚åº¦"""
        complexity = 1  # åŸºç¡€å¤æ‚åº¦
        
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.AsyncFor)):
                complexity += 1
            elif isinstance(child, ast.ExceptHandler):
                complexity += 1
            elif isinstance(child, (ast.And, ast.Or)):
                complexity += 1
        
        return complexity
    
    def _analyze_naming_conventions(self, tree: ast.AST):
        """åˆ†æå‘½åè§„èŒƒ"""
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                if not re.match(r'^[a-z_][a-z0-9_]*$', node.name):
                    self.issues['naming_conventions'].append({
                        'type': 'function',
                        'name': node.name,
                        'issue': 'Should use snake_case'
                    })
            
            elif isinstance(node, ast.ClassDef):
                if not re.match(r'^[A-Z][a-zA-Z0-9]*$', node.name):
                    self.issues['naming_conventions'].append({
                        'type': 'class',
                        'name': node.name,
                        'issue': 'Should use PascalCase'
                    })
            
            elif isinstance(node, ast.Constant):
                if isinstance(node.value, str) and node.value.isupper():
                    if not re.match(r'^[A-Z_][A-Z0-9_]*$', node.value):
                        self.issues['naming_conventions'].append({
                            'type': 'constant',
                            'name': node.value,
                            'issue': 'Should use UPPER_CASE'
                        })
    
    def _analyze_docstrings(self, tree: ast.AST):
        """åˆ†ææ–‡æ¡£å­—ç¬¦ä¸²"""
        for node in ast.walk(tree):
            if isinstance(node, (ast.FunctionDef, ast.ClassDef)):
                if not ast.get_docstring(node):
                    self.issues['missing_docstrings'].append({
                        'type': 'function' if isinstance(node, ast.FunctionDef) else 'class',
                        'name': node.name
                    })
    
    def _calculate_metrics(self, content: str, tree: ast.AST):
        """è®¡ç®—ä»£ç æŒ‡æ ‡"""
        lines = content.split('\n')
        
        # åŸºæœ¬æŒ‡æ ‡
        self.metrics['total_lines'] = len(lines)
        self.metrics['non_empty_lines'] = len([l for l in lines if l.strip()])
        self.metrics['comment_lines'] = len([l for l in lines if l.strip().startswith('#')])
        
        # ä»£ç è¡Œæ•°
        code_lines = len([l for l in lines if l.strip() and not l.strip().startswith('#')])
        self.metrics['code_lines'] = code_lines
        
        # æ³¨é‡Šç‡
        if code_lines > 0:
            self.metrics['comment_ratio'] = self.metrics['comment_lines'] / code_lines
        else:
            self.metrics['comment_ratio'] = 0
        
        # å‡½æ•°å’Œç±»æ•°é‡
        functions = [n for n in ast.walk(tree) if isinstance(n, ast.FunctionDef)]
        classes = [n for n in ast.walk(tree) if isinstance(n, ast.ClassDef)]
        
        self.metrics['function_count'] = len(functions)
        self.metrics['class_count'] = len(classes)
        
        # å¹³å‡å‡½æ•°é•¿åº¦
        if functions:
            total_function_lines = sum(f.end_lineno - f.lineno for f in functions)
            self.metrics['avg_function_length'] = total_function_lines / len(functions)
        else:
            self.metrics['avg_function_length'] = 0

def generate_quality_report(files: List[str]) -> Dict[str, Any]:
    """ç”Ÿæˆä»£ç è´¨é‡æŠ¥å‘Š"""
    analyzer = CodeQualityAnalyzer()
    results = []
    
    for filepath in files:
        if filepath.endswith('.py'):
            result = analyzer.analyze_file(filepath)
            results.append(result)
    
    # æ±‡æ€»æŠ¥å‘Š
    total_issues = defaultdict(int)
    total_metrics = defaultdict(float)
    file_count = 0
    
    for result in results:
        if 'error' not in result:
            file_count += 1
            for issue_type, issues in result['issues'].items():
                total_issues[issue_type] += len(issues)
            
            for metric, value in result['metrics'].items():
                if isinstance(value, (int, float)):
                    total_metrics[metric] += value
    
    # è®¡ç®—å¹³å‡å€¼
    for metric in total_metrics:
        if file_count > 0:
            total_metrics[metric] = total_metrics[metric] / file_count
    
    return {
        'summary': {
            'files_analyzed': file_count,
            'total_issues': sum(total_issues.values()),
            'issue_breakdown': dict(total_issues),
            'average_metrics': dict(total_metrics)
        },
        'file_details': results
    }

# ä»£ç è´¨é‡å»ºè®®
QUALITY_RECOMMENDATIONS = {
    "é«˜ä¼˜å…ˆçº§": [
        "æ·»åŠ ç±»å‹æ³¨è§£æå‡ä»£ç å¯è¯»æ€§",
        "ä¸ºæ‰€æœ‰å…¬å…±å‡½æ•°æ·»åŠ æ–‡æ¡£å­—ç¬¦ä¸²",
        "å‡å°‘å‡½æ•°å¤æ‚åº¦ï¼Œæ‹†åˆ†å¤§å‹å‡½æ•°",
        "ç§»é™¤æœªä½¿ç”¨çš„å¯¼å…¥è¯­å¥"
    ],
    "ä¸­ä¼˜å…ˆçº§": [
        "éµå¾ªPEP 8å‘½åè§„èŒƒ",
        "æ·»åŠ å•å…ƒæµ‹è¯•è¦†ç›–æ ¸å¿ƒåŠŸèƒ½",
        "ä½¿ç”¨å¸¸é‡æ›¿ä»£é­”æ³•æ•°å­—",
        "æ”¹è¿›é”™è¯¯å¤„ç†å’Œå¼‚å¸¸ç®¡ç†"
    ],
    "ä½ä¼˜å…ˆçº§": [
        "æ·»åŠ ä»£ç æ³¨é‡Šè§£é‡Šå¤æ‚é€»è¾‘",
        "ä½¿ç”¨æšä¸¾æ›¿ä»£å­—ç¬¦ä¸²å¸¸é‡",
        "å®ç°è®¾è®¡æ¨¡å¼æå‡ä»£ç ç»“æ„",
        "æ·»åŠ æ€§èƒ½ç›‘æ§å’Œæ—¥å¿—è®°å½•"
    ]
}

def main():
    """ä¸»å‡½æ•°"""
    # åˆ†æé¡¹ç›®æ–‡ä»¶
    files_to_analyze = [
        'complete_project_system.py',
        'unified_quant_system.py',
        'security_fixes.py',
        'performance_analysis.py'
    ]
    
    # è¿‡æ»¤å­˜åœ¨çš„æ–‡ä»¶
    existing_files = [f for f in files_to_analyze if os.path.exists(f)]
    
    if not existing_files:
        print("æ²¡æœ‰æ‰¾åˆ°è¦åˆ†æçš„æ–‡ä»¶")
        return
    
    print("ğŸ” å¼€å§‹ä»£ç è´¨é‡åˆ†æ...")
    print("=" * 50)
    
    report = generate_quality_report(existing_files)
    
    # è¾“å‡ºæ‘˜è¦
    summary = report['summary']
    print(f"\nğŸ“Š åˆ†ææ‘˜è¦:")
    print(f"  åˆ†ææ–‡ä»¶æ•°: {summary['files_analyzed']}")
    print(f"  æ€»é—®é¢˜æ•°: {summary['total_issues']}")
    
    print(f"\nğŸ“‹ é—®é¢˜åˆ†ç±»:")
    for issue_type, count in summary['issue_breakdown'].items():
        print(f"  {issue_type}: {count}")
    
    print(f"\nğŸ“ˆ ä»£ç æŒ‡æ ‡:")
    for metric, value in summary['average_metrics'].items():
        if isinstance(value, float):
            print(f"  {metric}: {value:.2f}")
        else:
            print(f"  {metric}: {value}")
    
    # è¾“å‡ºè¯¦ç»†é—®é¢˜
    print(f"\nğŸ” è¯¦ç»†é—®é¢˜:")
    for file_result in report['file_details']:
        if 'error' in file_result:
            print(f"\nâŒ {file_result['filepath']}: {file_result['error']}")
            continue
        
        filepath = file_result['filepath']
        issues = file_result['issues']
        
        if not any(issues.values()):
            print(f"\nâœ… {filepath}: æ— é—®é¢˜")
            continue
        
        print(f"\nğŸ“„ {filepath}:")
        for issue_type, issue_list in issues.items():
            if issue_list:
                print(f"  {issue_type}:")
                for issue in issue_list[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    if isinstance(issue, dict):
                        print(f"    - {issue}")
                    else:
                        print(f"    - {issue}")
                if len(issue_list) > 5:
                    print(f"    ... è¿˜æœ‰ {len(issue_list) - 5} ä¸ªé—®é¢˜")
    
    # è¾“å‡ºå»ºè®®
    print(f"\nğŸ’¡ ä»£ç è´¨é‡æ”¹è¿›å»ºè®®:")
    print("=" * 50)
    for priority, recommendations in QUALITY_RECOMMENDATIONS.items():
        print(f"\n{priority}:")
        for i, rec in enumerate(recommendations, 1):
            print(f"  {i}. {rec}")

if __name__ == "__main__":
    main()
