#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
CODEXé‡åŒ–äº¤æ˜“ç³»ç»Ÿ - æ€§èƒ½ä¼˜åŒ–å™¨
è‡ªåŠ¨åˆ†æå¹¶ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½
"""

import asyncio
import time
import json
import os
import psutil
import gc
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from concurrent.futures import ThreadPoolExecutor
import sqlite3


class PerformanceOptimizer:
    """æ€§èƒ½ä¼˜åŒ–å™¨"""

    def __init__(self):
        self.metrics = {
            "start_time": datetime.now(),
            "optimizations_applied": [],
            "performance_metrics": {},
            "recommendations": []
        }

    def get_system_metrics(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
        try:
            # CPUä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=1)
            cpu_count = psutil.cpu_count()

            # å†…å­˜ä½¿ç”¨
            memory = psutil.virtual_memory()
            swap = psutil.swap_memory()

            # ç£ç›˜ä½¿ç”¨
            disk = psutil.disk_usage('/')

            # ç½‘ç»œIO
            network = psutil.net_io_counters()

            # è¿›ç¨‹ä¿¡æ¯
            process_count = len(psutil.pids())

            return {
                "timestamp": datetime.now().isoformat(),
                "cpu": {
                    "usage_percent": cpu_percent,
                    "count": cpu_count,
                    "load_average": os.getloadavg() if hasattr(os, 'getloadavg') else None
                },
                "memory": {
                    "total": memory.total,
                    "available": memory.available,
                    "percent": memory.percent,
                    "used": memory.used,
                    "free": memory.free
                },
                "swap": {
                    "total": swap.total,
                    "used": swap.used,
                    "free": swap.free,
                    "percent": swap.percent
                },
                "disk": {
                    "total": disk.total,
                    "used": disk.used,
                    "free": disk.free,
                    "percent": (disk.used / disk.total) * 100
                },
                "network": {
                    "bytes_sent": network.bytes_sent,
                    "bytes_recv": network.bytes_recv,
                    "packets_sent": network.packets_sent,
                    "packets_recv": network.packets_recv
                },
                "processes": {
                    "count": process_count
                }
            }
        except Exception as e:
            return {"error": str(e)}

    def check_api_performance(self, base_url: str = "http://localhost:8000") -> Dict[str, Any]:
        """æ£€æŸ¥APIæ€§èƒ½"""
        import requests

        endpoints = [
            "/tasks",
            "/health"
        ]

        results = {}

        for endpoint in endpoints:
            try:
                url = f"{base_url}{endpoint}"
                start_time = time.time()

                response = requests.get(url, timeout=5)
                end_time = time.time()

                response_time = (end_time - start_time) * 1000  # ms

                results[endpoint] = {
                    "status_code": response.status_code,
                    "response_time_ms": round(response_time, 2),
                    "success": response.status_code == 200
                }
            except Exception as e:
                results[endpoint] = {
                    "error": str(e),
                    "success": False
                }

        return results

    def optimize_memory(self) -> Dict[str, Any]:
        """å†…å­˜ä¼˜åŒ–"""
        try:
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()

            # è·å–å½“å‰å†…å­˜ä½¿ç”¨
            memory = psutil.virtual_memory()

            optimizations = []

            # æ£€æŸ¥å†…å­˜ä½¿ç”¨ç‡
            if memory.percent > 80:
                optimizations.append({
                    "type": "memory_cleanup",
                    "action": "å¼ºåˆ¶åƒåœ¾å›æ”¶",
                    "result": "å·²å®Œæˆ"
                })

            return {
                "success": True,
                "optimizations": optimizations,
                "memory_after": {
                    "percent": memory.percent,
                    "used_gb": round(memory.used / (1024**3), 2),
                    "available_gb": round(memory.available / (1024**3), 2)
                }
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }

    def optimize_database(self, db_path: str = "tasks.db") -> Dict[str, Any]:
        """æ•°æ®åº“ä¼˜åŒ–"""
        try:
            if not os.path.exists(db_path):
                return {"success": False, "error": "æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨"}

            optimizations = []

            with sqlite3.connect(db_path) as conn:
                # åˆ†ææ•°æ®åº“
                conn.execute("ANALYZE")

                # æ¸…ç†æ•°æ®åº“
                conn.execute("VACUUM")

                # ä¼˜åŒ–è¡¨
                cursor = conn.cursor()
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
                tables = cursor.fetchall()

                for table in tables:
                    table_name = table[0]
                    # é‡æ–°ç´¢å¼•
                    cursor.execute(f"REINDEX {table_name}")
                    optimizations.append(f"å·²ä¼˜åŒ–è¡¨: {table_name}")

            return {
                "success": True,
                "optimizations": optimizations,
                "tables_optimized": len(tables)
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }

    def clear_cache(self) -> Dict[str, Any]:
        """æ¸…ç†ç¼“å­˜"""
        try:
            cache_dirs = [
                "__pycache__",
                ".pytest_cache",
                "node_modules/.cache",
                "dist",
                "build"
            ]

            cleared_files = 0
            cleared_size = 0

            for cache_dir in cache_dirs:
                if os.path.exists(cache_dir):
                    for root, dirs, files in os.walk(cache_dir):
                        for file in files:
                            file_path = os.path.join(root, file)
                            try:
                                size = os.path.getsize(file_path)
                                os.remove(file_path)
                                cleared_files += 1
                                cleared_size += size
                            except:
                                pass

            return {
                "success": True,
                "files_cleared": cleared_files,
                "size_mb": round(cleared_size / (1024**2), 2)
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }

    def generate_recommendations(self, metrics: Dict[str, Any]) -> List[Dict[str, str]]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []

        # CPUå»ºè®®
        if metrics.get("cpu", {}).get("usage_percent", 0) > 80:
            recommendations.append({
                "category": "CPU",
                "issue": "CPUä½¿ç”¨ç‡è¿‡é«˜",
                "recommendation": "è€ƒè™‘å‡çº§CPUæˆ–ä¼˜åŒ–ç®—æ³•å¤æ‚åº¦",
                "priority": "é«˜"
            })

        # å†…å­˜å»ºè®®
        if metrics.get("memory", {}).get("percent", 0) > 80:
            recommendations.append({
                "category": "å†…å­˜",
                "issue": "å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜",
                "recommendation": "å¢åŠ å†…å­˜æˆ–ä¼˜åŒ–å†…å­˜ä½¿ç”¨",
                "priority": "é«˜"
            })

        # ç£ç›˜å»ºè®®
        if metrics.get("disk", {}).get("percent", 0) > 90:
            recommendations.append({
                "category": "ç£ç›˜",
                "issue": "ç£ç›˜ç©ºé—´ä¸è¶³",
                "recommendation": "æ¸…ç†ä¸´æ—¶æ–‡ä»¶æˆ–æ‰©å±•ç£ç›˜ç©ºé—´",
                "priority": "é«˜"
            })

        # è¿›ç¨‹å»ºè®®
        if metrics.get("processes", {}).get("count", 0) > 100:
            recommendations.append({
                "category": "è¿›ç¨‹",
                "issue": "è¿›ç¨‹æ•°é‡è¿‡å¤š",
                "recommendation": "å…³é—­ä¸å¿…è¦çš„è¿›ç¨‹",
                "priority": "ä¸­"
            })

        return recommendations

    async def run_optimization(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´ä¼˜åŒ–"""
        print("=" * 60)
        print("ğŸš€ CODEXæ€§èƒ½ä¼˜åŒ–å™¨ - å¼€å§‹ä¼˜åŒ–")
        print("=" * 60)
        print()

        # 1. è·å–ç³»ç»ŸæŒ‡æ ‡
        print("[1/5] æ­£åœ¨åˆ†æç³»ç»Ÿæ€§èƒ½...")
        metrics = self.get_system_metrics()
        self.metrics["performance_metrics"] = metrics

        # 2. æ£€æŸ¥APIæ€§èƒ½
        print("[2/5] æ­£åœ¨æ£€æŸ¥APIæ€§èƒ½...")
        api_perf = self.check_api_performance()
        self.metrics["api_performance"] = api_perf

        # 3. å†…å­˜ä¼˜åŒ–
        print("[3/5] æ­£åœ¨ä¼˜åŒ–å†…å­˜...")
        mem_opt = self.optimize_memory()
        if mem_opt["success"]:
            self.metrics["optimizations_applied"].append(mem_opt)
            print(f"  âœ“ æ¸…ç†äº† {mem_opt['memory_after']['used_gb']}GB å†…å­˜")

        # 4. æ•°æ®åº“ä¼˜åŒ–
        print("[4/5] æ­£åœ¨ä¼˜åŒ–æ•°æ®åº“...")
        db_opt = self.optimize_database()
        if db_opt["success"]:
            self.metrics["optimizations_applied"].append(db_opt)
            print(f"  âœ“ ä¼˜åŒ–äº† {db_opt['tables_optimized']} ä¸ªè¡¨")

        # 5. æ¸…ç†ç¼“å­˜
        print("[5/5] æ­£åœ¨æ¸…ç†ç¼“å­˜...")
        cache_opt = self.clear_cache()
        if cache_opt["success"]:
            self.metrics["optimizations_applied"].append(cache_opt)
            print(f"  âœ“ æ¸…ç†äº† {cache_opt['files_cleared']} ä¸ªç¼“å­˜æ–‡ä»¶")

        # ç”Ÿæˆå»ºè®®
        print()
        print("ç”Ÿæˆä¼˜åŒ–å»ºè®®...")
        recommendations = self.generate_recommendations(metrics)
        self.metrics["recommendations"] = recommendations

        # æ‰“å°å»ºè®®
        if recommendations:
            print()
            print("ğŸ” æ€§èƒ½å»ºè®®:")
            for rec in recommendations:
                print(f"  [{rec['priority']}] {rec['category']}: {rec['recommendation']}")
        else:
            print("  âœ“ ç³»ç»Ÿæ€§èƒ½è‰¯å¥½ï¼Œæ— ç‰¹æ®Šå»ºè®®")

        print()
        print("=" * 60)
        print("âœ… ä¼˜åŒ–å®Œæˆ!")
        print("=" * 60)

        return self.metrics

    def save_report(self, filepath: str = "performance_report.json"):
        """ä¿å­˜ä¼˜åŒ–æŠ¥å‘Š"""
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(self.metrics, f, ensure_ascii=False, indent=2, default=str)
            print(f"ğŸ“Š æŠ¥å‘Šå·²ä¿å­˜åˆ°: {filepath}")
        except Exception as e:
            print(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    optimizer = PerformanceOptimizer()

    # è¿è¡Œä¼˜åŒ–
    asyncio.run(optimizer.run_optimization())

    # ä¿å­˜æŠ¥å‘Š
    optimizer.save_report("performance_report.json")

    # æ‰“å°æ€»ç»“
    print()
    print("ğŸ“ˆ ä¼˜åŒ–æ€»ç»“:")
    print(f"  ä¼˜åŒ–é¡¹ç›®: {len(optimizer.metrics['optimizations_applied'])}")
    print(f"  ç³»ç»Ÿå»ºè®®: {len(optimizer.metrics['recommendations'])}")
    print(f"  è¿è¡Œæ—¶é—´: {optimizer.metrics['start_time'].strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    main()
