#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
éªŒè¯ç³»ç»Ÿæµ‹è¯•è„šæœ¬
æµ‹è¯•CPUç›‘æ§ã€ä»»åŠ¡è®¡æ—¶ã€ç»“æœéªŒè¯åŠŸèƒ½
"""

import sys
import time
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
)
logger = logging.getLogger("TEST")

# å¯¼å…¥ç³»ç»Ÿç»„ä»¶
try:
    from complete_project_system import (
        CPUMonitor,
        validate_optimization_results,
        run_ma_strategy,
        calculate_strategy_performance
    )
    logger.info("âœ… æˆåŠŸå¯¼å…¥ç³»ç»Ÿç»„ä»¶")
except Exception as e:
    logger.error(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

# ==================== Test 1: CPUç›‘æ§ç³»ç»Ÿ ====================
def test_cpu_monitoring():
    """æµ‹è¯•CPUç›‘æ§åŠŸèƒ½"""
    logger.info("\n" + "="*60)
    logger.info("ğŸ“Š Test 1: CPUç›‘æ§ç³»ç»Ÿ")
    logger.info("="*60)

    try:
        # åˆ›å»ºCPUç›‘æ§å®ä¾‹
        cpu_monitor = CPUMonitor()
        logger.info("âœ… CPUMonitorå®ä¾‹åˆ›å»ºæˆåŠŸ")

        # æ•è·åŸºçº¿
        baseline = cpu_monitor.capture_baseline()
        if baseline:
            logger.info(f"âœ… åŸºçº¿æ•è·æˆåŠŸ: {baseline}")
        else:
            logger.error("âŒ åŸºçº¿æ•è·å¤±è´¥")
            return False

        # æ¨¡æ‹Ÿä¸€äº›è®¡ç®—
        logger.info("â³ æ¨¡æ‹Ÿè®¡ç®—ä¸­ï¼ˆ3ç§’ï¼‰...")
        time.sleep(3)

        # æ•è·å¿«ç…§
        snapshot = cpu_monitor.capture_snapshot()
        if snapshot:
            logger.info(f"âœ… å¿«ç…§æ•è·æˆåŠŸ: CPU={snapshot['cpu_percent']:.1f}%")
        else:
            logger.error("âŒ å¿«ç…§æ•è·å¤±è´¥")
            return False

        # ç”ŸæˆæŠ¥å‘Š
        report = cpu_monitor.generate_report()
        if report:
            logger.info(f"âœ… æŠ¥å‘Šç”ŸæˆæˆåŠŸ")
            logger.info(f"   CPUå˜åŒ–: {report['cpu_change']:+.1f}%")
            logger.info(f"   å†…å­˜å˜åŒ–: {report['memory_change']:+.1f}MB")
            logger.info(f"   æ´»è·ƒè¿›ç¨‹: {report['active_children']}/{report.get('peak_children', 'N/A')}")
            return True
        else:
            logger.error("âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥")
            return False

    except Exception as e:
        logger.error(f"âŒ Test 1å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False

# ==================== Test 2: ç»“æœéªŒè¯ç³»ç»Ÿ ====================
def test_result_validation():
    """æµ‹è¯•ç»“æœéªŒè¯åŠŸèƒ½"""
    logger.info("\n" + "="*60)
    logger.info("ğŸ” Test 2: ç»“æœéªŒè¯ç³»ç»Ÿ")
    logger.info("="*60)

    try:
        # åˆ›å»ºæ¨¡æ‹Ÿç»“æœ
        mock_results = [
            {
                'strategy_name': f'MA_Test_{i}',
                'sharpe_ratio': 1.2 + np.random.randn() * 0.3,
                'total_return': 15 + np.random.randn() * 8,
                'max_drawdown': -8 + np.random.randn() * 2,
            }
            for i in range(50)
        ]

        logger.info(f"âœ… åˆ›å»º{len(mock_results)}ä¸ªæ¨¡æ‹Ÿç»“æœ")

        # éªŒè¯ç»“æœ
        validation_report = validate_optimization_results(mock_results)
        if validation_report:
            logger.info(f"âœ… éªŒè¯æŠ¥å‘Šç”ŸæˆæˆåŠŸ")
            logger.info(f"   çŠ¶æ€: {validation_report['status']}")
            logger.info(f"   Sharpeå¤šæ ·æ€§: {validation_report['diversity_metrics']['sharpe_ratio_unique']}/{len(mock_results)}")
            logger.info(f"   å¤šæ ·æ€§æ¯”ç‡: {validation_report['diversity_metrics']['sharpe_ratio_diversity']:.1%}")
            logger.info(f"   æ£€æŸ¥é€šè¿‡: {validation_report['checks']['all_passed']}")
            logger.info(f"   Sharpeç»Ÿè®¡: å¹³å‡={validation_report['statistics']['sharpe_mean']:.2f}, "
                       f"æ ‡å‡†å·®={validation_report['statistics']['sharpe_std']:.2f}")
            return validation_report['checks']['all_passed']
        else:
            logger.error("âŒ éªŒè¯æŠ¥å‘Šç”Ÿæˆå¤±è´¥")
            return False

    except Exception as e:
        logger.error(f"âŒ Test 2å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False

# ==================== Test 3: ä»»åŠ¡è®¡æ—¶ ====================
def test_task_timing():
    """æµ‹è¯•ä»»åŠ¡è®¡æ—¶åŠŸèƒ½"""
    logger.info("\n" + "="*60)
    logger.info("â±ï¸ Test 3: ä»»åŠ¡è®¡æ—¶ç³»ç»Ÿ")
    logger.info("="*60)

    try:
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        dates = pd.date_range(end=datetime.now(), periods=500, freq='D')
        test_data = []
        price = 100
        for date in dates:
            price += np.random.randn() * 2
            test_data.append({
                'date': date,
                'open': price,
                'high': price + 1,
                'low': price - 1,
                'close': price,
                'volume': 1000000,
            })

        df = pd.DataFrame(test_data)
        logger.info(f"âœ… åˆ›å»º{len(df)}è¡Œæµ‹è¯•æ•°æ®")

        # æµ‹è¯•MAç­–ç•¥è®¡ç®—è®¡æ—¶
        logger.info("â³ è¿è¡ŒMAç­–ç•¥è®¡ç®—...")
        wall_start = time.time()
        cpu_start = time.process_time()

        result = run_ma_strategy(df, short_window=5, long_window=20)

        wall_time_ms = (time.time() - wall_start) * 1000
        cpu_time_ms = (time.process_time() - cpu_start) * 1000
        cpu_efficiency = (cpu_time_ms / wall_time_ms * 100) if wall_time_ms > 0 else 0

        if result:
            logger.info(f"âœ… ç­–ç•¥è®¡ç®—å®Œæˆ")
            logger.info(f"   å£é’Ÿæ—¶é—´: {wall_time_ms:.2f}ms")
            logger.info(f"   CPUæ—¶é—´: {cpu_time_ms:.2f}ms")
            logger.info(f"   CPUæ•ˆç‡: {cpu_efficiency:.1f}%")
            logger.info(f"   Sharpeæ¯”ç‡: {result['sharpe_ratio']:.3f}")

            # éªŒè¯è®¡æ—¶æ•°æ®åˆç†æ€§
            if wall_time_ms > 0 and cpu_efficiency > 50:
                logger.info("âœ… è®¡æ—¶æ•°æ®åˆç†")
                return True
            else:
                logger.warning("âš ï¸ è®¡æ—¶æ•°æ®å¼‚å¸¸")
                return False
        else:
            logger.error("âŒ ç­–ç•¥è®¡ç®—å¤±è´¥")
            return False

    except Exception as e:
        logger.error(f"âŒ Test 3å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False

# ==================== Test 4: å°è§„æ¨¡å¤šç­–ç•¥ä¼˜åŒ– ====================
def test_small_optimization():
    """æµ‹è¯•å°è§„æ¨¡ç­–ç•¥ä¼˜åŒ–"""
    logger.info("\n" + "="*60)
    logger.info("ğŸš€ Test 4: å°è§„æ¨¡å¤šç­–ç•¥ä¼˜åŒ–")
    logger.info("="*60)

    try:
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        dates = pd.date_range(end=datetime.now(), periods=500, freq='D')
        test_data = []
        price = 100
        for date in dates:
            price += np.random.randn() * 2
            test_data.append({
                'date': date,
                'open': price,
                'high': price + 1,
                'low': price - 1,
                'close': price,
                'volume': 1000000,
            })

        df = pd.DataFrame(test_data)
        logger.info(f"âœ… åˆ›å»º{len(df)}è¡Œæµ‹è¯•æ•°æ®")

        # æµ‹è¯•å°‘æ•°MAå‚æ•°ç»„åˆ
        logger.info("â³ è¿è¡Œå°è§„æ¨¡ä¼˜åŒ–ï¼ˆåªæµ‹è¯•5ä¸ªMAå‚æ•°ç»„åˆï¼‰...")

        results = []
        timing_stats = []
        start_time = time.time()

        for short in [3, 5, 10, 15, 20]:
            for long in [30, 50]:
                if short < long:
                    # è®¡æ—¶
                    wall_start = time.time()
                    cpu_start = time.process_time()

                    result = run_ma_strategy(df, short, long)

                    wall_time_ms = (time.time() - wall_start) * 1000
                    cpu_time_ms = (time.process_time() - cpu_start) * 1000

                    if result:
                        result['_timing'] = {
                            'wall_time_ms': round(wall_time_ms, 2),
                            'cpu_time_ms': round(cpu_time_ms, 2),
                            'cpu_efficiency': round(cpu_time_ms / wall_time_ms * 100, 1),
                        }
                        results.append(result)
                        timing_stats.append(result['_timing'])
                        logger.info(f"âœ“ MA({short},{long}): Sharpe={result['sharpe_ratio']:.3f}, "
                                  f"æ—¶é—´={wall_time_ms:.1f}ms")

        elapsed = time.time() - start_time
        logger.info(f"âœ… ä¼˜åŒ–å®Œæˆ: {len(results)}ä¸ªç»“æœ, è€—æ—¶{elapsed:.2f}ç§’")

        # è®¡æ—¶ç»Ÿè®¡
        if timing_stats:
            wall_times = [t['wall_time_ms'] for t in timing_stats]
            logger.info(f"â±ï¸ è®¡æ—¶ç»Ÿè®¡:")
            logger.info(f"   å¹³å‡è€—æ—¶: {np.mean(wall_times):.1f}ms")
            logger.info(f"   èŒƒå›´: {min(wall_times):.1f}ms - {max(wall_times):.1f}ms")
            logger.info(f"   å¹³å‡CPUæ•ˆç‡: {np.mean([t['cpu_efficiency'] for t in timing_stats]):.1f}%")

        # éªŒè¯ç»“æœ
        if len(results) > 0:
            validation_report = validate_optimization_results(results)
            logger.info(f"âœ… éªŒè¯æŠ¥å‘Š:")
            logger.info(f"   çŠ¶æ€: {validation_report['status']}")
            logger.info(f"   Sharpeå¤šæ ·æ€§: {validation_report['diversity_metrics']['sharpe_ratio_unique']}/{len(results)}")
            return True
        else:
            logger.error("âŒ æ²¡æœ‰ç»“æœè¿”å›")
            return False

    except Exception as e:
        logger.error(f"âŒ Test 4å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False

# ==================== ä¸»æµ‹è¯•å‡½æ•° ====================
def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("\n" + "â–ˆ"*60)
    logger.info("éªŒè¯ç³»ç»Ÿå®Œæ•´æµ‹è¯•å¥—ä»¶")
    logger.info("â–ˆ"*60)

    tests = [
        ("CPUç›‘æ§", test_cpu_monitoring),
        ("ç»“æœéªŒè¯", test_result_validation),
        ("ä»»åŠ¡è®¡æ—¶", test_task_timing),
        ("å°è§„æ¨¡ä¼˜åŒ–", test_small_optimization),
    ]

    results = {}
    for test_name, test_func in tests:
        try:
            results[test_name] = test_func()
        except Exception as e:
            logger.error(f"âŒ {test_name}å¼‚å¸¸: {e}")
            results[test_name] = False

    # æ€»ç»“
    logger.info("\n" + "="*60)
    logger.info("ğŸ“‹ æµ‹è¯•æ€»ç»“")
    logger.info("="*60)
    passed = sum(1 for v in results.values() if v)
    total = len(results)

    for test_name, result in results.items():
        status = "âœ… PASS" if result else "âŒ FAIL"
        logger.info(f"{status}: {test_name}")

    logger.info(f"\næ€»ä½“: {passed}/{total} æµ‹è¯•é€šè¿‡")

    if passed == total:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå°±ç»ª")
        return True
    else:
        logger.warning(f"âš ï¸ {total - passed}ä¸ªæµ‹è¯•å¤±è´¥")
        return False

if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)
